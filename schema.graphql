# This file was generated based on ".graphqlconfig". Do not edit manually.

schema {
    query: query_root
    subscription: subscription_root
}

"whether this query should be cached (Hasura Cloud only)"
directive @cached(
    "refresh the cache entry"
    refresh: Boolean! = false,
    "measured in seconds"
    ttl: Int! = 60
) on QUERY

"columns and relationships of \"attribute\""
type attribute {
    "An array relationship"
    attribute_counts(
        "distinct select on columns"
        distinct_on: [fa2_attribute_count_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [fa2_attribute_count_order_by!],
        "filter the rows returned"
        where: fa2_attribute_count_bool_exp
    ): [fa2_attribute_count!]!
    id: bigint!
    name: String
    "An array relationship"
    tokens(
        "distinct select on columns"
        distinct_on: [token_attribute_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_attribute_order_by!],
        "filter the rows returned"
        where: token_attribute_bool_exp
    ): [token_attribute!]!
    type: String
    value: String
}

"columns and relationships of \"currency\""
type currency {
    decimals: Int
    "An object relationship"
    fa: fa
    fa_contract: String
    id: bigint!
    "An object relationship"
    token: token
    token_pk: bigint
    type: token_type
}

"columns and relationships of \"dutch_auction\""
type dutch_auction {
    amount: Int
    amount_left: Int
    bigmap_key: bigint
    "An object relationship"
    currency: currency
    currency_id: bigint
    end_price: bigint
    end_price_xtz: bigint
    end_time: timestamptz
    expiry: timestamptz
    "An object relationship"
    fa: fa!
    fa_contract: String!
    hash: String
    id: bigint!
    level: Int
    "An object relationship"
    marketplace: marketplace_contract!
    marketplace_contract: String!
    ophash: String
    "An array relationship"
    sales(
        "distinct select on columns"
        distinct_on: [dutch_auction_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_sale_order_by!],
        "filter the rows returned"
        where: dutch_auction_sale_bool_exp
    ): [dutch_auction_sale!]!
    "An object relationship"
    seller: holder
    seller_address: String
    shares(
        "JSON select path"
        path: String
    ): jsonb
    start_price: bigint
    start_price_xtz: bigint
    start_time: timestamptz
    status: auction_status
    timestamp: timestamptz
    "An object relationship"
    token: token
    token_pk: bigint
    update_level: Int
    update_ophash: String
    update_timestamp: timestamptz
}

"columns and relationships of \"dutch_auction_sale\""
type dutch_auction_sale {
    amount: Int
    "An object relationship"
    buyer: holder
    buyer_address: String
    "An object relationship"
    currency: currency
    currency_id: bigint
    "An object relationship"
    dutch_auction: dutch_auction
    dutch_auction_id: bigint
    id: bigint!
    level: Int
    "An object relationship"
    marketplace: marketplace_contract!
    marketplace_contract: String!
    ophash: String
    price: bigint
    price_xtz: bigint
    "An object relationship"
    seller: holder
    seller_address: String
    "An object relationship"
    sender: holder
    sender_address: String
    timestamp: timestamptz
    "An object relationship"
    token: token
    token_pk: bigint
}

"columns and relationships of \"english_auction\""
type english_auction {
    "An array relationship"
    bids(
        "distinct select on columns"
        distinct_on: [english_auction_bid_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_bid_order_by!],
        "filter the rows returned"
        where: english_auction_bid_bool_exp
    ): [english_auction_bid!]!
    bigmap_key: bigint
    "An object relationship"
    currency: currency
    currency_id: bigint
    duration: Int
    end_time: timestamptz
    extension_time: Int
    "An object relationship"
    fa: fa!
    fa_contract: String!
    hash: String
    highest_bid: bigint
    highest_bid_xtz: bigint
    "An object relationship"
    highest_bidder: holder
    highest_bidder_address: String
    id: bigint!
    level: Int
    "An object relationship"
    marketplace: marketplace_contract!
    marketplace_contract: String!
    ophash: String
    price_increment: bigint
    price_increment_xtz: bigint
    reserve: bigint
    reserve_xtz: bigint
    "An object relationship"
    seller: holder
    seller_address: String
    shares(
        "JSON select path"
        path: String
    ): jsonb
    start_time: timestamptz
    status: auction_status
    timestamp: timestamptz
    "An object relationship"
    token: token
    token_pk: bigint
    update_level: Int
    update_ophash: String
    update_timestamp: timestamptz
}

"columns and relationships of \"english_auction_bid\""
type english_auction_bid {
    amount: bigint
    amount_xtz: bigint
    "An object relationship"
    auction: english_auction
    "An object relationship"
    bidder: holder
    bidder_address: String
    "An object relationship"
    currency: currency
    currency_id: bigint
    english_auction_id: bigint
    id: bigint!
    level: Int
    "An object relationship"
    marketplace: marketplace_contract!
    marketplace_contract: String!
    ophash: String
    timestamp: timestamptz
}

"columns and relationships of \"event\""
type event {
    amount: bigint
    "An object relationship"
    creator: holder!
    creator_address: String!
    "An object relationship"
    currency: currency
    currency_id: bigint
    event_type: event_type
    "An object relationship"
    fa: fa
    fa_contract: String
    id: bigint!
    level: Int!
    "An object relationship"
    marketplace: marketplace_contract
    marketplace_contract: String
    marketplace_event_type: marketplace_event_type
    marketplace_object_id: bigint
    ob_contract: Boolean!
    ophash: String
    price: bigint
    price_xtz: bigint
    "An object relationship"
    recipient: holder
    recipient_address: String
    reverted: Boolean
    timestamp: timestamptz!
    "An object relationship"
    token: token
    token_pk: bigint
}

"columns and relationships of \"fa\""
type fa {
    active_auctions: Int
    active_listing: Int
    "An array relationship"
    attribute_counts(
        "distinct select on columns"
        distinct_on: [fa2_attribute_count_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [fa2_attribute_count_order_by!],
        "filter the rows returned"
        where: fa2_attribute_count_bool_exp
    ): [fa2_attribute_count!]!
    category: String
    "An array relationship"
    collaborators(
        "distinct select on columns"
        distinct_on: [invitation_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [invitation_order_by!],
        "filter the rows returned"
        where: invitation_bool_exp
    ): [invitation!]!
    collection_id: String
    collection_type: collection_type
    contract: String!
    "An object relationship"
    creator: holder
    creator_address: String
    description: String
    "An array relationship"
    dutch_auctions(
        "distinct select on columns"
        distinct_on: [dutch_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_order_by!],
        "filter the rows returned"
        where: dutch_auction_bool_exp
    ): [dutch_auction!]!
    editions: bigint
    "An array relationship"
    english_auctions(
        "distinct select on columns"
        distinct_on: [english_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_order_by!],
        "filter the rows returned"
        where: english_auction_bool_exp
    ): [english_auction!]!
    "An array relationship"
    events(
        "distinct select on columns"
        distinct_on: [event_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_order_by!],
        "filter the rows returned"
        where: event_bool_exp
    ): [event!]!
    floor_price: bigint
    index_contract_metadata: Boolean
    items: Int
    last_metadata_update: timestamptz
    ledger_type: ledger_type
    level: Int
    "An array relationship"
    listings(
        "distinct select on columns"
        distinct_on: [listing_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_order_by!],
        "filter the rows returned"
        where: listing_bool_exp
    ): [listing!]!
    live: Boolean!
    logo: String
    metadata: String
    name: String
    "An array relationship"
    offers(
        "distinct select on columns"
        distinct_on: [offer_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [offer_order_by!],
        "filter the rows returned"
        where: offer_bool_exp
    ): [offer!]!
    "An array relationship"
    open_edition(
        "distinct select on columns"
        distinct_on: [open_edition_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [open_edition_order_by!],
        "filter the rows returned"
        where: open_edition_bool_exp
    ): [open_edition!]!
    originated: String
    owners: Int
    path: String
    short_name: String
    timestamp: timestamptz
    token_link: String
    "An array relationship"
    tokens(
        "distinct select on columns"
        distinct_on: [token_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_order_by!],
        "filter the rows returned"
        where: token_bool_exp
    ): [token!]!
    twitter: String
    type: fa_type
    tzip16_key: String
    updated_attributes_counts: timestamptz
    verified_creators(
        "JSON select path"
        path: String
    ): jsonb
    volume_24h: bigint
    volume_total: bigint
    website: String
}

"columns and relationships of \"fa2_attribute_count\""
type fa2_attribute_count {
    "An object relationship"
    attribute: attribute!
    attribute_id: bigint!
    editions: bigint
    "An object relationship"
    fa: fa!
    fa_contract: String!
    id: bigint!
    tokens: bigint
}

"columns and relationships of \"gallery_attribute_count\""
type gallery_attribute_count {
    "An object relationship"
    attribute: attribute
    attribute_id: bigint
    editions: bigint
    gallery_pk: bigint!
    id: bigint!
    tokens: bigint
}

"columns and relationships of \"holder\""
type holder {
    address: String!
    alias: String
    "An array relationship"
    collaborations(
        "distinct select on columns"
        distinct_on: [invitation_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [invitation_order_by!],
        "filter the rows returned"
        where: invitation_bool_exp
    ): [invitation!]!
    "An array relationship"
    created_tokens(
        "distinct select on columns"
        distinct_on: [token_creator_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_creator_order_by!],
        "filter the rows returned"
        where: token_creator_bool_exp
    ): [token_creator!]!
    description: String
    discord: String
    dns: String
    "An array relationship"
    dutch_auctions_bought(
        "distinct select on columns"
        distinct_on: [dutch_auction_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_sale_order_by!],
        "filter the rows returned"
        where: dutch_auction_sale_bool_exp
    ): [dutch_auction_sale!]!
    "An array relationship"
    dutch_auctions_created(
        "distinct select on columns"
        distinct_on: [dutch_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_order_by!],
        "filter the rows returned"
        where: dutch_auction_bool_exp
    ): [dutch_auction!]!
    "An array relationship"
    dutch_auctions_sold(
        "distinct select on columns"
        distinct_on: [dutch_auction_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_sale_order_by!],
        "filter the rows returned"
        where: dutch_auction_sale_bool_exp
    ): [dutch_auction_sale!]!
    email: String
    "An array relationship"
    english_auction_bids(
        "distinct select on columns"
        distinct_on: [english_auction_bid_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_bid_order_by!],
        "filter the rows returned"
        where: english_auction_bid_bool_exp
    ): [english_auction_bid!]!
    "An array relationship"
    english_auctions_created(
        "distinct select on columns"
        distinct_on: [english_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_order_by!],
        "filter the rows returned"
        where: english_auction_bool_exp
    ): [english_auction!]!
    "An array relationship"
    english_auctions_highest_bidder(
        "distinct select on columns"
        distinct_on: [english_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_order_by!],
        "filter the rows returned"
        where: english_auction_bool_exp
    ): [english_auction!]!
    ethereum: String
    "An array relationship"
    events_creator(
        "distinct select on columns"
        distinct_on: [event_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_order_by!],
        "filter the rows returned"
        where: event_bool_exp
    ): [event!]!
    "An array relationship"
    events_recipient(
        "distinct select on columns"
        distinct_on: [event_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_order_by!],
        "filter the rows returned"
        where: event_bool_exp
    ): [event!]!
    "An array relationship"
    fa2s_created(
        "distinct select on columns"
        distinct_on: [fa_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [fa_order_by!],
        "filter the rows returned"
        where: fa_bool_exp
    ): [fa!]!
    facebook: String
    flag: flag_type
    github: String
    gitlab: String
    "An array relationship"
    held_tokens(
        "distinct select on columns"
        distinct_on: [token_holder_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_holder_order_by!],
        "filter the rows returned"
        where: token_holder_bool_exp
    ): [token_holder!]!
    inserted_at: timestamptz
    instagram: String
    last_metadata_update: timestamptz
    "An array relationship"
    listings_bought(
        "distinct select on columns"
        distinct_on: [listing_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_sale_order_by!],
        "filter the rows returned"
        where: listing_sale_bool_exp
    ): [listing_sale!]!
    "An array relationship"
    listings_created(
        "distinct select on columns"
        distinct_on: [listing_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_order_by!],
        "filter the rows returned"
        where: listing_bool_exp
    ): [listing!]!
    "An array relationship"
    listings_sold(
        "distinct select on columns"
        distinct_on: [listing_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_sale_order_by!],
        "filter the rows returned"
        where: listing_sale_bool_exp
    ): [listing_sale!]!
    logo: String
    medium: String
    "An array relationship"
    offers_accepted(
        "distinct select on columns"
        distinct_on: [offer_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [offer_order_by!],
        "filter the rows returned"
        where: offer_bool_exp
    ): [offer!]!
    "An array relationship"
    offers_created(
        "distinct select on columns"
        distinct_on: [offer_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [offer_order_by!],
        "filter the rows returned"
        where: offer_bool_exp
    ): [offer!]!
    "An array relationship"
    open_edition_created(
        "distinct select on columns"
        distinct_on: [open_edition_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [open_edition_order_by!],
        "filter the rows returned"
        where: open_edition_bool_exp
    ): [open_edition!]!
    "An array relationship"
    operator_operators(
        "distinct select on columns"
        distinct_on: [token_operator_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_operator_order_by!],
        "filter the rows returned"
        where: token_operator_bool_exp
    ): [token_operator!]!
    "An array relationship"
    owner_operators(
        "distinct select on columns"
        distinct_on: [token_operator_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_operator_order_by!],
        "filter the rows returned"
        where: token_operator_bool_exp
    ): [token_operator!]!
    "An array relationship"
    receiver_royalties(
        "distinct select on columns"
        distinct_on: [royalties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [royalties_order_by!],
        "filter the rows returned"
        where: royalties_bool_exp
    ): [royalties!]!
    reddit: String
    "An array relationship"
    sales_stats(
        "distinct select on columns"
        distinct_on: [sales_stat_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [sales_stat_order_by!],
        "filter the rows returned"
        where: sales_stat_bool_exp
    ): [sales_stat!]!
    slack: String
    support: String
    telegram: String
    twitter: String
    tzdomain: String
    website: String
}

"columns and relationships of \"invitation\""
type invitation {
    collaborator_address: String!
    "An object relationship"
    fa: fa!
    fa_contract: String!
    history(
        "JSON select path"
        path: String
    ): jsonb
    "An object relationship"
    holder: holder!
    id: bigint!
    level: Int!
    status: invitation_type
    timestamp: timestamptz
    update_timestamp: timestamptz
}

"columns and relationships of \"listing\""
type listing {
    amount: Int
    amount_left: Int
    bigmap_key: bigint
    "An object relationship"
    currency: currency
    currency_id: bigint
    end_price: bigint
    expiry: timestamptz
    "An object relationship"
    fa: fa!
    fa_contract: String!
    id: bigint!
    level: Int
    "An array relationship"
    listing_sales(
        "distinct select on columns"
        distinct_on: [listing_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_sale_order_by!],
        "filter the rows returned"
        where: listing_sale_bool_exp
    ): [listing_sale!]!
    "An object relationship"
    marketplace: marketplace_contract!
    marketplace_contract: String!
    ophash: String
    price: bigint
    price_xtz: bigint
    "An object relationship"
    seller: holder!
    seller_address: String!
    shares(
        "JSON select path"
        path: String
    ): jsonb
    start_price: bigint
    status: auction_status
    "An object relationship"
    target: holder
    target_address: String
    timestamp: timestamptz
    "An object relationship"
    token: token
    token_pk: bigint
    update_level: Int
    update_ophash: String
    update_timestamp: timestamptz
}

"columns and relationships of \"listing_sale\""
type listing_sale {
    amount: Int
    "An object relationship"
    buyer: holder
    buyer_address: String
    id: bigint!
    level: Int
    "An object relationship"
    listing: listing
    listing_id: bigint
    "An object relationship"
    marketplace: marketplace_contract!
    marketplace_contract: String!
    ophash: String
    price: bigint
    price_xtz: bigint
    "An object relationship"
    seller: holder
    seller_address: String
    "An object relationship"
    sender: holder
    sender_address: String
    timestamp: timestamptz
    "An object relationship"
    token: token
    token_pk: bigint
}

"columns and relationships of \"marketplace_contract\""
type marketplace_contract {
    contract: String!
    "An array relationship"
    events(
        "distinct select on columns"
        distinct_on: [event_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_order_by!],
        "filter the rows returned"
        where: event_bool_exp
    ): [event!]!
    group: String
    name: String
    subgroup: String
}

"columns and relationships of \"offer\""
type offer {
    bigmap_key: bigint
    "An object relationship"
    buyer: holder
    buyer_address: String
    collection_offer: String
    "An object relationship"
    currency: currency
    currency_id: bigint
    expiry: timestamptz
    "An object relationship"
    fa: fa!
    fa_contract: String!
    id: bigint!
    level: Int
    "An object relationship"
    marketplace: marketplace_contract!
    marketplace_contract: String!
    ophash: String
    price: bigint
    price_xtz: bigint
    "An object relationship"
    seller: holder
    seller_address: String
    shares(
        "JSON select path"
        path: String
    ): jsonb
    status: auction_status
    "An object relationship"
    target: holder
    target_address: String
    timestamp: timestamptz
    "An object relationship"
    token: token
    token_pk: bigint
    update_level: Int
    update_ophash: String
    update_timestamp: timestamptz
}

"columns and relationships of \"open_edition\""
type open_edition {
    airdrop_capacity: Int
    burn_recipe(
        "JSON select path"
        path: String
    ): jsonb
    end_time: timestamptz
    "An object relationship"
    fa: fa!
    fa_contract: String!
    level: Int
    max_per_wallet: Int
    ophash: String
    price: bigint
    "An object relationship"
    seller: holder
    seller_address: String
    shares(
        "JSON select path"
        path: String
    ): jsonb
    shares_total: Int
    start_time: timestamptz
    timestamp: timestamptz
    "An object relationship"
    token: token!
    token_pk: bigint!
    valid_royalties: Boolean!
}

"columns and relationships of \"open_edition_active\""
type open_edition_active {
    airdrop_capacity: Int
    burn_recipe(
        "JSON select path"
        path: String
    ): jsonb
    end_time: timestamptz
    "An object relationship"
    fa: fa
    fa_contract: String
    level: Int
    max_per_wallet: Int
    ophash: String
    price: bigint
    "An object relationship"
    seller: holder
    seller_address: String
    shares(
        "JSON select path"
        path: String
    ): jsonb
    shares_total: Int
    start_time: timestamptz
    timestamp: timestamptz
    "An object relationship"
    token: token
    token_pk: bigint
}

type query_root {
    "fetch data from the table: \"attribute\""
    attribute(
        "distinct select on columns"
        distinct_on: [attribute_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [attribute_order_by!],
        "filter the rows returned"
        where: attribute_bool_exp
    ): [attribute!]!
    "fetch data from the table: \"attribute\" using primary key columns"
    attribute_by_pk(id: bigint!): attribute
    "fetch data from the table: \"currency\""
    currency(
        "distinct select on columns"
        distinct_on: [currency_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [currency_order_by!],
        "filter the rows returned"
        where: currency_bool_exp
    ): [currency!]!
    "fetch data from the table: \"currency\" using primary key columns"
    currency_by_pk(id: bigint!): currency
    "fetch data from the table: \"dutch_auction\""
    dutch_auction(
        "distinct select on columns"
        distinct_on: [dutch_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_order_by!],
        "filter the rows returned"
        where: dutch_auction_bool_exp
    ): [dutch_auction!]!
    "fetch data from the table: \"dutch_auction\" using primary key columns"
    dutch_auction_by_pk(id: bigint!): dutch_auction
    "fetch data from the table: \"dutch_auction_sale\""
    dutch_auction_sale(
        "distinct select on columns"
        distinct_on: [dutch_auction_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_sale_order_by!],
        "filter the rows returned"
        where: dutch_auction_sale_bool_exp
    ): [dutch_auction_sale!]!
    "fetch data from the table: \"dutch_auction_sale\" using primary key columns"
    dutch_auction_sale_by_pk(id: bigint!): dutch_auction_sale
    "fetch data from the table: \"english_auction\""
    english_auction(
        "distinct select on columns"
        distinct_on: [english_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_order_by!],
        "filter the rows returned"
        where: english_auction_bool_exp
    ): [english_auction!]!
    "fetch data from the table: \"english_auction_bid\""
    english_auction_bid(
        "distinct select on columns"
        distinct_on: [english_auction_bid_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_bid_order_by!],
        "filter the rows returned"
        where: english_auction_bid_bool_exp
    ): [english_auction_bid!]!
    "fetch data from the table: \"english_auction_bid\" using primary key columns"
    english_auction_bid_by_pk(id: bigint!): english_auction_bid
    "fetch data from the table: \"english_auction\" using primary key columns"
    english_auction_by_pk(id: bigint!): english_auction
    "fetch data from the table: \"event\""
    event(
        "distinct select on columns"
        distinct_on: [event_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_order_by!],
        "filter the rows returned"
        where: event_bool_exp
    ): [event!]!
    "fetch data from the table: \"event\" using primary key columns"
    event_by_pk(id: bigint!, timestamp: timestamptz!): event
    "fetch data from the table: \"fa\""
    fa(
        "distinct select on columns"
        distinct_on: [fa_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [fa_order_by!],
        "filter the rows returned"
        where: fa_bool_exp
    ): [fa!]!
    "fetch data from the table: \"fa2_attribute_count\""
    fa2_attribute_count(
        "distinct select on columns"
        distinct_on: [fa2_attribute_count_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [fa2_attribute_count_order_by!],
        "filter the rows returned"
        where: fa2_attribute_count_bool_exp
    ): [fa2_attribute_count!]!
    "fetch data from the table: \"fa2_attribute_count\" using primary key columns"
    fa2_attribute_count_by_pk(id: bigint!): fa2_attribute_count
    "fetch data from the table: \"fa\" using primary key columns"
    fa_by_pk(contract: String!): fa
    "fetch data from the table: \"gallery_attribute_count\""
    gallery_attribute_count(
        "distinct select on columns"
        distinct_on: [gallery_attribute_count_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [gallery_attribute_count_order_by!],
        "filter the rows returned"
        where: gallery_attribute_count_bool_exp
    ): [gallery_attribute_count!]!
    "fetch data from the table: \"gallery_attribute_count\" using primary key columns"
    gallery_attribute_count_by_pk(id: bigint!): gallery_attribute_count
    "fetch data from the table: \"holder\""
    holder(
        "distinct select on columns"
        distinct_on: [holder_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [holder_order_by!],
        "filter the rows returned"
        where: holder_bool_exp
    ): [holder!]!
    "fetch data from the table: \"holder\" using primary key columns"
    holder_by_pk(address: String!): holder
    "fetch data from the table: \"invitation\""
    invitation(
        "distinct select on columns"
        distinct_on: [invitation_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [invitation_order_by!],
        "filter the rows returned"
        where: invitation_bool_exp
    ): [invitation!]!
    "fetch data from the table: \"invitation\" using primary key columns"
    invitation_by_pk(id: bigint!): invitation
    "fetch data from the table: \"listing\""
    listing(
        "distinct select on columns"
        distinct_on: [listing_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_order_by!],
        "filter the rows returned"
        where: listing_bool_exp
    ): [listing!]!
    "fetch data from the table: \"listing\" using primary key columns"
    listing_by_pk(id: bigint!): listing
    "fetch data from the table: \"listing_sale\""
    listing_sale(
        "distinct select on columns"
        distinct_on: [listing_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_sale_order_by!],
        "filter the rows returned"
        where: listing_sale_bool_exp
    ): [listing_sale!]!
    "fetch data from the table: \"listing_sale\" using primary key columns"
    listing_sale_by_pk(id: bigint!): listing_sale
    "fetch data from the table: \"marketplace_contract\""
    marketplace_contract(
        "distinct select on columns"
        distinct_on: [marketplace_contract_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [marketplace_contract_order_by!],
        "filter the rows returned"
        where: marketplace_contract_bool_exp
    ): [marketplace_contract!]!
    "fetch data from the table: \"marketplace_contract\" using primary key columns"
    marketplace_contract_by_pk(contract: String!): marketplace_contract
    "fetch data from the table: \"offer\""
    offer(
        "distinct select on columns"
        distinct_on: [offer_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [offer_order_by!],
        "filter the rows returned"
        where: offer_bool_exp
    ): [offer!]!
    "fetch data from the table: \"offer\" using primary key columns"
    offer_by_pk(id: bigint!): offer
    "An array relationship"
    open_edition(
        "distinct select on columns"
        distinct_on: [open_edition_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [open_edition_order_by!],
        "filter the rows returned"
        where: open_edition_bool_exp
    ): [open_edition!]!
    "fetch data from the table: \"open_edition_active\""
    open_edition_active(
        "distinct select on columns"
        distinct_on: [open_edition_active_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [open_edition_active_order_by!],
        "filter the rows returned"
        where: open_edition_active_bool_exp
    ): [open_edition_active!]!
    "fetch data from the table: \"open_edition\" using primary key columns"
    open_edition_by_pk(token_pk: bigint!): open_edition
    "An array relationship"
    royalties(
        "distinct select on columns"
        distinct_on: [royalties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [royalties_order_by!],
        "filter the rows returned"
        where: royalties_bool_exp
    ): [royalties!]!
    "fetch data from the table: \"royalties\" using primary key columns"
    royalties_by_pk(id: bigint!): royalties
    "fetch data from the table: \"sales_stat\""
    sales_stat(
        "distinct select on columns"
        distinct_on: [sales_stat_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [sales_stat_order_by!],
        "filter the rows returned"
        where: sales_stat_bool_exp
    ): [sales_stat!]!
    "fetch data from the table: \"sales_stat\" using primary key columns"
    sales_stat_by_pk(id: bigint!): sales_stat
    "fetch data from the table: \"tag\""
    tag(
        "distinct select on columns"
        distinct_on: [tag_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tag_order_by!],
        "filter the rows returned"
        where: tag_bool_exp
    ): [tag!]!
    "fetch data from the table: \"tag\" using primary key columns"
    tag_by_pk(id: bigint!): tag
    "fetch data from the table: \"tezos_storage\""
    tezos_storage(
        "distinct select on columns"
        distinct_on: [tezos_storage_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tezos_storage_order_by!],
        "filter the rows returned"
        where: tezos_storage_bool_exp
    ): [tezos_storage!]!
    "fetch data from the table: \"tezos_storage\" using primary key columns"
    tezos_storage_by_pk(id: bigint!): tezos_storage
    "fetch data from the table: \"token\""
    token(
        "distinct select on columns"
        distinct_on: [token_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_order_by!],
        "filter the rows returned"
        where: token_bool_exp
    ): [token!]!
    "fetch data from the table: \"token_attribute\""
    token_attribute(
        "distinct select on columns"
        distinct_on: [token_attribute_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_attribute_order_by!],
        "filter the rows returned"
        where: token_attribute_bool_exp
    ): [token_attribute!]!
    "fetch data from the table: \"token_attribute\" using primary key columns"
    token_attribute_by_pk(id: bigint!): token_attribute
    "fetch data from the table: \"token\" using primary key columns"
    token_by_pk(pk: bigint!): token
    "fetch data from the table: \"token_creator\""
    token_creator(
        "distinct select on columns"
        distinct_on: [token_creator_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_creator_order_by!],
        "filter the rows returned"
        where: token_creator_bool_exp
    ): [token_creator!]!
    "fetch data from the table: \"token_creator\" using primary key columns"
    token_creator_by_pk(creator_address: String!, token_pk: bigint!): token_creator
    "fetch data from the table: \"token_holder\""
    token_holder(
        "distinct select on columns"
        distinct_on: [token_holder_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_holder_order_by!],
        "filter the rows returned"
        where: token_holder_bool_exp
    ): [token_holder!]!
    "fetch data from the table: \"token_holder\" using primary key columns"
    token_holder_by_pk(holder_address: String!, token_pk: bigint!): token_holder
    "fetch data from the table: \"token_operator\""
    token_operator(
        "distinct select on columns"
        distinct_on: [token_operator_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_operator_order_by!],
        "filter the rows returned"
        where: token_operator_bool_exp
    ): [token_operator!]!
    "fetch data from the table: \"token_operator\" using primary key columns"
    token_operator_by_pk(id: bigint!): token_operator
    "fetch data from the table: \"token_registry\""
    token_registry(
        "distinct select on columns"
        distinct_on: [token_registry_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_registry_order_by!],
        "filter the rows returned"
        where: token_registry_bool_exp
    ): [token_registry!]!
    "fetch data from the table: \"token_registry\" using primary key columns"
    token_registry_by_pk(address: String!): token_registry
    "fetch data from the table: \"token_tag\""
    token_tag(
        "distinct select on columns"
        distinct_on: [token_tag_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_tag_order_by!],
        "filter the rows returned"
        where: token_tag_bool_exp
    ): [token_tag!]!
    "fetch data from the table: \"token_tag\" using primary key columns"
    token_tag_by_pk(id: bigint!): token_tag
    "fetch data from the table: \"tzd_domain\""
    tzd_domain(
        "distinct select on columns"
        distinct_on: [tzd_domain_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tzd_domain_order_by!],
        "filter the rows returned"
        where: tzd_domain_bool_exp
    ): [tzd_domain!]!
    "fetch data from the table: \"tzd_domain\" using primary key columns"
    tzd_domain_by_pk(id: String!): tzd_domain
    "fetch data from the table: \"tzd_record\""
    tzd_record(
        "distinct select on columns"
        distinct_on: [tzd_record_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tzd_record_order_by!],
        "filter the rows returned"
        where: tzd_record_bool_exp
    ): [tzd_record!]!
    "fetch data from the table: \"tzd_record\" using primary key columns"
    tzd_record_by_pk(id: String!): tzd_record
    "fetch data from the table: \"tzd_tld\""
    tzd_tld(
        "distinct select on columns"
        distinct_on: [tzd_tld_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tzd_tld_order_by!],
        "filter the rows returned"
        where: tzd_tld_bool_exp
    ): [tzd_tld!]!
    "fetch data from the table: \"tzd_tld\" using primary key columns"
    tzd_tld_by_pk(id: String!): tzd_tld
}

"columns and relationships of \"royalties\""
type royalties {
    amount: Int!
    decimals: Int!
    "An object relationship"
    holder: holder!
    id: bigint!
    receiver_address: String!
    "An object relationship"
    token: token!
    token_pk: bigint!
}

"columns and relationships of \"sales_stat\""
type sales_stat {
    id: bigint!
    interval_days: Int
    rank: Int
    "An object relationship"
    subject: holder!
    subject_address: String!
    type: sales_stat_type
    volume: bigint
}

type subscription_root {
    "fetch data from the table: \"attribute\""
    attribute(
        "distinct select on columns"
        distinct_on: [attribute_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [attribute_order_by!],
        "filter the rows returned"
        where: attribute_bool_exp
    ): [attribute!]!
    "fetch data from the table: \"attribute\" using primary key columns"
    attribute_by_pk(id: bigint!): attribute
    "fetch data from the table in a streaming manner: \"attribute\""
    attribute_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [attribute_stream_cursor_input]!,
        "filter the rows returned"
        where: attribute_bool_exp
    ): [attribute!]!
    "fetch data from the table: \"currency\""
    currency(
        "distinct select on columns"
        distinct_on: [currency_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [currency_order_by!],
        "filter the rows returned"
        where: currency_bool_exp
    ): [currency!]!
    "fetch data from the table: \"currency\" using primary key columns"
    currency_by_pk(id: bigint!): currency
    "fetch data from the table in a streaming manner: \"currency\""
    currency_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [currency_stream_cursor_input]!,
        "filter the rows returned"
        where: currency_bool_exp
    ): [currency!]!
    "fetch data from the table: \"dutch_auction\""
    dutch_auction(
        "distinct select on columns"
        distinct_on: [dutch_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_order_by!],
        "filter the rows returned"
        where: dutch_auction_bool_exp
    ): [dutch_auction!]!
    "fetch data from the table: \"dutch_auction\" using primary key columns"
    dutch_auction_by_pk(id: bigint!): dutch_auction
    "fetch data from the table: \"dutch_auction_sale\""
    dutch_auction_sale(
        "distinct select on columns"
        distinct_on: [dutch_auction_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_sale_order_by!],
        "filter the rows returned"
        where: dutch_auction_sale_bool_exp
    ): [dutch_auction_sale!]!
    "fetch data from the table: \"dutch_auction_sale\" using primary key columns"
    dutch_auction_sale_by_pk(id: bigint!): dutch_auction_sale
    "fetch data from the table in a streaming manner: \"dutch_auction_sale\""
    dutch_auction_sale_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [dutch_auction_sale_stream_cursor_input]!,
        "filter the rows returned"
        where: dutch_auction_sale_bool_exp
    ): [dutch_auction_sale!]!
    "fetch data from the table in a streaming manner: \"dutch_auction\""
    dutch_auction_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [dutch_auction_stream_cursor_input]!,
        "filter the rows returned"
        where: dutch_auction_bool_exp
    ): [dutch_auction!]!
    "fetch data from the table: \"english_auction\""
    english_auction(
        "distinct select on columns"
        distinct_on: [english_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_order_by!],
        "filter the rows returned"
        where: english_auction_bool_exp
    ): [english_auction!]!
    "fetch data from the table: \"english_auction_bid\""
    english_auction_bid(
        "distinct select on columns"
        distinct_on: [english_auction_bid_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_bid_order_by!],
        "filter the rows returned"
        where: english_auction_bid_bool_exp
    ): [english_auction_bid!]!
    "fetch data from the table: \"english_auction_bid\" using primary key columns"
    english_auction_bid_by_pk(id: bigint!): english_auction_bid
    "fetch data from the table in a streaming manner: \"english_auction_bid\""
    english_auction_bid_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [english_auction_bid_stream_cursor_input]!,
        "filter the rows returned"
        where: english_auction_bid_bool_exp
    ): [english_auction_bid!]!
    "fetch data from the table: \"english_auction\" using primary key columns"
    english_auction_by_pk(id: bigint!): english_auction
    "fetch data from the table in a streaming manner: \"english_auction\""
    english_auction_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [english_auction_stream_cursor_input]!,
        "filter the rows returned"
        where: english_auction_bool_exp
    ): [english_auction!]!
    "fetch data from the table: \"event\""
    event(
        "distinct select on columns"
        distinct_on: [event_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_order_by!],
        "filter the rows returned"
        where: event_bool_exp
    ): [event!]!
    "fetch data from the table: \"event\" using primary key columns"
    event_by_pk(id: bigint!, timestamp: timestamptz!): event
    "fetch data from the table in a streaming manner: \"event\""
    event_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [event_stream_cursor_input]!,
        "filter the rows returned"
        where: event_bool_exp
    ): [event!]!
    "fetch data from the table: \"fa\""
    fa(
        "distinct select on columns"
        distinct_on: [fa_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [fa_order_by!],
        "filter the rows returned"
        where: fa_bool_exp
    ): [fa!]!
    "fetch data from the table: \"fa2_attribute_count\""
    fa2_attribute_count(
        "distinct select on columns"
        distinct_on: [fa2_attribute_count_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [fa2_attribute_count_order_by!],
        "filter the rows returned"
        where: fa2_attribute_count_bool_exp
    ): [fa2_attribute_count!]!
    "fetch data from the table: \"fa2_attribute_count\" using primary key columns"
    fa2_attribute_count_by_pk(id: bigint!): fa2_attribute_count
    "fetch data from the table in a streaming manner: \"fa2_attribute_count\""
    fa2_attribute_count_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [fa2_attribute_count_stream_cursor_input]!,
        "filter the rows returned"
        where: fa2_attribute_count_bool_exp
    ): [fa2_attribute_count!]!
    "fetch data from the table: \"fa\" using primary key columns"
    fa_by_pk(contract: String!): fa
    "fetch data from the table in a streaming manner: \"fa\""
    fa_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [fa_stream_cursor_input]!,
        "filter the rows returned"
        where: fa_bool_exp
    ): [fa!]!
    "fetch data from the table: \"gallery_attribute_count\""
    gallery_attribute_count(
        "distinct select on columns"
        distinct_on: [gallery_attribute_count_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [gallery_attribute_count_order_by!],
        "filter the rows returned"
        where: gallery_attribute_count_bool_exp
    ): [gallery_attribute_count!]!
    "fetch data from the table: \"gallery_attribute_count\" using primary key columns"
    gallery_attribute_count_by_pk(id: bigint!): gallery_attribute_count
    "fetch data from the table in a streaming manner: \"gallery_attribute_count\""
    gallery_attribute_count_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [gallery_attribute_count_stream_cursor_input]!,
        "filter the rows returned"
        where: gallery_attribute_count_bool_exp
    ): [gallery_attribute_count!]!
    "fetch data from the table: \"holder\""
    holder(
        "distinct select on columns"
        distinct_on: [holder_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [holder_order_by!],
        "filter the rows returned"
        where: holder_bool_exp
    ): [holder!]!
    "fetch data from the table: \"holder\" using primary key columns"
    holder_by_pk(address: String!): holder
    "fetch data from the table in a streaming manner: \"holder\""
    holder_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [holder_stream_cursor_input]!,
        "filter the rows returned"
        where: holder_bool_exp
    ): [holder!]!
    "fetch data from the table: \"invitation\""
    invitation(
        "distinct select on columns"
        distinct_on: [invitation_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [invitation_order_by!],
        "filter the rows returned"
        where: invitation_bool_exp
    ): [invitation!]!
    "fetch data from the table: \"invitation\" using primary key columns"
    invitation_by_pk(id: bigint!): invitation
    "fetch data from the table in a streaming manner: \"invitation\""
    invitation_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [invitation_stream_cursor_input]!,
        "filter the rows returned"
        where: invitation_bool_exp
    ): [invitation!]!
    "fetch data from the table: \"listing\""
    listing(
        "distinct select on columns"
        distinct_on: [listing_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_order_by!],
        "filter the rows returned"
        where: listing_bool_exp
    ): [listing!]!
    "fetch data from the table: \"listing\" using primary key columns"
    listing_by_pk(id: bigint!): listing
    "fetch data from the table: \"listing_sale\""
    listing_sale(
        "distinct select on columns"
        distinct_on: [listing_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_sale_order_by!],
        "filter the rows returned"
        where: listing_sale_bool_exp
    ): [listing_sale!]!
    "fetch data from the table: \"listing_sale\" using primary key columns"
    listing_sale_by_pk(id: bigint!): listing_sale
    "fetch data from the table in a streaming manner: \"listing_sale\""
    listing_sale_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [listing_sale_stream_cursor_input]!,
        "filter the rows returned"
        where: listing_sale_bool_exp
    ): [listing_sale!]!
    "fetch data from the table in a streaming manner: \"listing\""
    listing_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [listing_stream_cursor_input]!,
        "filter the rows returned"
        where: listing_bool_exp
    ): [listing!]!
    "fetch data from the table: \"marketplace_contract\""
    marketplace_contract(
        "distinct select on columns"
        distinct_on: [marketplace_contract_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [marketplace_contract_order_by!],
        "filter the rows returned"
        where: marketplace_contract_bool_exp
    ): [marketplace_contract!]!
    "fetch data from the table: \"marketplace_contract\" using primary key columns"
    marketplace_contract_by_pk(contract: String!): marketplace_contract
    "fetch data from the table in a streaming manner: \"marketplace_contract\""
    marketplace_contract_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [marketplace_contract_stream_cursor_input]!,
        "filter the rows returned"
        where: marketplace_contract_bool_exp
    ): [marketplace_contract!]!
    "fetch data from the table: \"offer\""
    offer(
        "distinct select on columns"
        distinct_on: [offer_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [offer_order_by!],
        "filter the rows returned"
        where: offer_bool_exp
    ): [offer!]!
    "fetch data from the table: \"offer\" using primary key columns"
    offer_by_pk(id: bigint!): offer
    "fetch data from the table in a streaming manner: \"offer\""
    offer_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [offer_stream_cursor_input]!,
        "filter the rows returned"
        where: offer_bool_exp
    ): [offer!]!
    "An array relationship"
    open_edition(
        "distinct select on columns"
        distinct_on: [open_edition_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [open_edition_order_by!],
        "filter the rows returned"
        where: open_edition_bool_exp
    ): [open_edition!]!
    "fetch data from the table: \"open_edition_active\""
    open_edition_active(
        "distinct select on columns"
        distinct_on: [open_edition_active_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [open_edition_active_order_by!],
        "filter the rows returned"
        where: open_edition_active_bool_exp
    ): [open_edition_active!]!
    "fetch data from the table in a streaming manner: \"open_edition_active\""
    open_edition_active_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [open_edition_active_stream_cursor_input]!,
        "filter the rows returned"
        where: open_edition_active_bool_exp
    ): [open_edition_active!]!
    "fetch data from the table: \"open_edition\" using primary key columns"
    open_edition_by_pk(token_pk: bigint!): open_edition
    "fetch data from the table in a streaming manner: \"open_edition\""
    open_edition_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [open_edition_stream_cursor_input]!,
        "filter the rows returned"
        where: open_edition_bool_exp
    ): [open_edition!]!
    "An array relationship"
    royalties(
        "distinct select on columns"
        distinct_on: [royalties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [royalties_order_by!],
        "filter the rows returned"
        where: royalties_bool_exp
    ): [royalties!]!
    "fetch data from the table: \"royalties\" using primary key columns"
    royalties_by_pk(id: bigint!): royalties
    "fetch data from the table in a streaming manner: \"royalties\""
    royalties_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [royalties_stream_cursor_input]!,
        "filter the rows returned"
        where: royalties_bool_exp
    ): [royalties!]!
    "fetch data from the table: \"sales_stat\""
    sales_stat(
        "distinct select on columns"
        distinct_on: [sales_stat_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [sales_stat_order_by!],
        "filter the rows returned"
        where: sales_stat_bool_exp
    ): [sales_stat!]!
    "fetch data from the table: \"sales_stat\" using primary key columns"
    sales_stat_by_pk(id: bigint!): sales_stat
    "fetch data from the table in a streaming manner: \"sales_stat\""
    sales_stat_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [sales_stat_stream_cursor_input]!,
        "filter the rows returned"
        where: sales_stat_bool_exp
    ): [sales_stat!]!
    "fetch data from the table: \"tag\""
    tag(
        "distinct select on columns"
        distinct_on: [tag_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tag_order_by!],
        "filter the rows returned"
        where: tag_bool_exp
    ): [tag!]!
    "fetch data from the table: \"tag\" using primary key columns"
    tag_by_pk(id: bigint!): tag
    "fetch data from the table in a streaming manner: \"tag\""
    tag_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [tag_stream_cursor_input]!,
        "filter the rows returned"
        where: tag_bool_exp
    ): [tag!]!
    "fetch data from the table: \"tezos_storage\""
    tezos_storage(
        "distinct select on columns"
        distinct_on: [tezos_storage_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tezos_storage_order_by!],
        "filter the rows returned"
        where: tezos_storage_bool_exp
    ): [tezos_storage!]!
    "fetch data from the table: \"tezos_storage\" using primary key columns"
    tezos_storage_by_pk(id: bigint!): tezos_storage
    "fetch data from the table in a streaming manner: \"tezos_storage\""
    tezos_storage_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [tezos_storage_stream_cursor_input]!,
        "filter the rows returned"
        where: tezos_storage_bool_exp
    ): [tezos_storage!]!
    "fetch data from the table: \"token\""
    token(
        "distinct select on columns"
        distinct_on: [token_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_order_by!],
        "filter the rows returned"
        where: token_bool_exp
    ): [token!]!
    "fetch data from the table: \"token_attribute\""
    token_attribute(
        "distinct select on columns"
        distinct_on: [token_attribute_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_attribute_order_by!],
        "filter the rows returned"
        where: token_attribute_bool_exp
    ): [token_attribute!]!
    "fetch data from the table: \"token_attribute\" using primary key columns"
    token_attribute_by_pk(id: bigint!): token_attribute
    "fetch data from the table in a streaming manner: \"token_attribute\""
    token_attribute_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [token_attribute_stream_cursor_input]!,
        "filter the rows returned"
        where: token_attribute_bool_exp
    ): [token_attribute!]!
    "fetch data from the table: \"token\" using primary key columns"
    token_by_pk(pk: bigint!): token
    "fetch data from the table: \"token_creator\""
    token_creator(
        "distinct select on columns"
        distinct_on: [token_creator_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_creator_order_by!],
        "filter the rows returned"
        where: token_creator_bool_exp
    ): [token_creator!]!
    "fetch data from the table: \"token_creator\" using primary key columns"
    token_creator_by_pk(creator_address: String!, token_pk: bigint!): token_creator
    "fetch data from the table in a streaming manner: \"token_creator\""
    token_creator_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [token_creator_stream_cursor_input]!,
        "filter the rows returned"
        where: token_creator_bool_exp
    ): [token_creator!]!
    "fetch data from the table: \"token_holder\""
    token_holder(
        "distinct select on columns"
        distinct_on: [token_holder_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_holder_order_by!],
        "filter the rows returned"
        where: token_holder_bool_exp
    ): [token_holder!]!
    "fetch data from the table: \"token_holder\" using primary key columns"
    token_holder_by_pk(holder_address: String!, token_pk: bigint!): token_holder
    "fetch data from the table in a streaming manner: \"token_holder\""
    token_holder_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [token_holder_stream_cursor_input]!,
        "filter the rows returned"
        where: token_holder_bool_exp
    ): [token_holder!]!
    "fetch data from the table: \"token_operator\""
    token_operator(
        "distinct select on columns"
        distinct_on: [token_operator_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_operator_order_by!],
        "filter the rows returned"
        where: token_operator_bool_exp
    ): [token_operator!]!
    "fetch data from the table: \"token_operator\" using primary key columns"
    token_operator_by_pk(id: bigint!): token_operator
    "fetch data from the table in a streaming manner: \"token_operator\""
    token_operator_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [token_operator_stream_cursor_input]!,
        "filter the rows returned"
        where: token_operator_bool_exp
    ): [token_operator!]!
    "fetch data from the table: \"token_registry\""
    token_registry(
        "distinct select on columns"
        distinct_on: [token_registry_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_registry_order_by!],
        "filter the rows returned"
        where: token_registry_bool_exp
    ): [token_registry!]!
    "fetch data from the table: \"token_registry\" using primary key columns"
    token_registry_by_pk(address: String!): token_registry
    "fetch data from the table in a streaming manner: \"token_registry\""
    token_registry_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [token_registry_stream_cursor_input]!,
        "filter the rows returned"
        where: token_registry_bool_exp
    ): [token_registry!]!
    "fetch data from the table in a streaming manner: \"token\""
    token_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [token_stream_cursor_input]!,
        "filter the rows returned"
        where: token_bool_exp
    ): [token!]!
    "fetch data from the table: \"token_tag\""
    token_tag(
        "distinct select on columns"
        distinct_on: [token_tag_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_tag_order_by!],
        "filter the rows returned"
        where: token_tag_bool_exp
    ): [token_tag!]!
    "fetch data from the table: \"token_tag\" using primary key columns"
    token_tag_by_pk(id: bigint!): token_tag
    "fetch data from the table in a streaming manner: \"token_tag\""
    token_tag_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [token_tag_stream_cursor_input]!,
        "filter the rows returned"
        where: token_tag_bool_exp
    ): [token_tag!]!
    "fetch data from the table: \"tzd_domain\""
    tzd_domain(
        "distinct select on columns"
        distinct_on: [tzd_domain_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tzd_domain_order_by!],
        "filter the rows returned"
        where: tzd_domain_bool_exp
    ): [tzd_domain!]!
    "fetch data from the table: \"tzd_domain\" using primary key columns"
    tzd_domain_by_pk(id: String!): tzd_domain
    "fetch data from the table in a streaming manner: \"tzd_domain\""
    tzd_domain_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [tzd_domain_stream_cursor_input]!,
        "filter the rows returned"
        where: tzd_domain_bool_exp
    ): [tzd_domain!]!
    "fetch data from the table: \"tzd_record\""
    tzd_record(
        "distinct select on columns"
        distinct_on: [tzd_record_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tzd_record_order_by!],
        "filter the rows returned"
        where: tzd_record_bool_exp
    ): [tzd_record!]!
    "fetch data from the table: \"tzd_record\" using primary key columns"
    tzd_record_by_pk(id: String!): tzd_record
    "fetch data from the table in a streaming manner: \"tzd_record\""
    tzd_record_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [tzd_record_stream_cursor_input]!,
        "filter the rows returned"
        where: tzd_record_bool_exp
    ): [tzd_record!]!
    "fetch data from the table: \"tzd_tld\""
    tzd_tld(
        "distinct select on columns"
        distinct_on: [tzd_tld_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tzd_tld_order_by!],
        "filter the rows returned"
        where: tzd_tld_bool_exp
    ): [tzd_tld!]!
    "fetch data from the table: \"tzd_tld\" using primary key columns"
    tzd_tld_by_pk(id: String!): tzd_tld
    "fetch data from the table in a streaming manner: \"tzd_tld\""
    tzd_tld_stream(
        "maximum number of rows returned in a single batch"
        batch_size: Int!,
        "cursor to stream the results returned by the query"
        cursor: [tzd_tld_stream_cursor_input]!,
        "filter the rows returned"
        where: tzd_tld_bool_exp
    ): [tzd_tld!]!
}

"columns and relationships of \"tag\""
type tag {
    id: bigint!
    name: String
    token_count: bigint
    "An array relationship"
    tokens(
        "distinct select on columns"
        distinct_on: [token_tag_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_tag_order_by!],
        "filter the rows returned"
        where: token_tag_bool_exp
    ): [token_tag!]!
}

"columns and relationships of \"tezos_storage\""
type tezos_storage {
    "An object relationship"
    fa: fa!
    fa_contract: String!
    id: bigint!
    tzip16_key: String
    tzip16_value: String
}

"columns and relationships of \"token\""
type token {
    artifact_uri: String
    "An array relationship"
    attributes(
        "distinct select on columns"
        distinct_on: [token_attribute_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_attribute_order_by!],
        "filter the rows returned"
        where: token_attribute_bool_exp
    ): [token_attribute!]!
    average: bigint
    "An array relationship"
    creators(
        "distinct select on columns"
        distinct_on: [token_creator_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_creator_order_by!],
        "filter the rows returned"
        where: token_creator_bool_exp
    ): [token_creator!]!
    decimals: Int
    description: String
    display_uri: String
    "An array relationship"
    dutch_auctions(
        "distinct select on columns"
        distinct_on: [dutch_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [dutch_auction_order_by!],
        "filter the rows returned"
        where: dutch_auction_bool_exp
    ): [dutch_auction!]!
    "An array relationship"
    english_auctions(
        "distinct select on columns"
        distinct_on: [english_auction_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [english_auction_order_by!],
        "filter the rows returned"
        where: english_auction_bool_exp
    ): [english_auction!]!
    "An array relationship"
    events(
        "distinct select on columns"
        distinct_on: [event_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [event_order_by!],
        "filter the rows returned"
        where: event_bool_exp
    ): [event!]!
    extra(
        "JSON select path"
        path: String
    ): jsonb
    "An object relationship"
    fa: fa!
    fa_contract: String!
    flag: flag_type
    highest_offer: bigint
    "An array relationship"
    holders(
        "distinct select on columns"
        distinct_on: [token_holder_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_holder_order_by!],
        "filter the rows returned"
        where: token_holder_bool_exp
    ): [token_holder!]!
    is_boolean_amount: Boolean
    last_listed: timestamptz
    last_metadata_update: timestamptz
    level: Int
    "An array relationship"
    listing_sales(
        "distinct select on columns"
        distinct_on: [listing_sale_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_sale_order_by!],
        "filter the rows returned"
        where: listing_sale_bool_exp
    ): [listing_sale!]!
    "An array relationship"
    listings(
        "distinct select on columns"
        distinct_on: [listing_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [listing_order_by!],
        "filter the rows returned"
        where: listing_bool_exp
    ): [listing!]!
    lowest_ask: bigint
    metadata: String
    metadata_status: metadata_status!
    mime: String
    name: String
    "An array relationship"
    offers(
        "distinct select on columns"
        distinct_on: [offer_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [offer_order_by!],
        "filter the rows returned"
        where: offer_bool_exp
    ): [offer!]!
    "An object relationship"
    open_edition: open_edition
    "An array relationship"
    operators(
        "distinct select on columns"
        distinct_on: [token_operator_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_operator_order_by!],
        "filter the rows returned"
        where: token_operator_bool_exp
    ): [token_operator!]!
    ophash: String
    pk: bigint!
    rights: String
    "An array relationship"
    royalties(
        "distinct select on columns"
        distinct_on: [royalties_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [royalties_order_by!],
        "filter the rows returned"
        where: royalties_bool_exp
    ): [royalties!]!
    supply: bigint
    symbol: String
    "An array relationship"
    tags(
        "distinct select on columns"
        distinct_on: [token_tag_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [token_tag_order_by!],
        "filter the rows returned"
        where: token_tag_bool_exp
    ): [token_tag!]!
    thumbnail_uri: String
    timestamp: timestamptz
    token_id: String!
    tzip16_key: String
}

"columns and relationships of \"token_attribute\""
type token_attribute {
    "An object relationship"
    attribute: attribute!
    attribute_id: bigint!
    id: bigint!
    "An object relationship"
    token: token!
    token_pk: bigint!
}

"columns and relationships of \"token_creator\""
type token_creator {
    creator_address: String!
    "An object relationship"
    holder: holder!
    "An object relationship"
    token: token!
    token_pk: bigint!
    verified: Boolean
}

"columns and relationships of \"token_holder\""
type token_holder {
    "An object relationship"
    holder: holder!
    holder_address: String!
    last_incremented_at: timestamptz
    quantity: numeric!
    "An object relationship"
    token: token!
    token_pk: bigint!
}

"columns and relationships of \"token_operator\""
type token_operator {
    allowed: Boolean!
    amount: numeric
    id: bigint!
    "An object relationship"
    operator: holder!
    operator_address: String!
    "An object relationship"
    owner: holder!
    owner_address: String!
    "An object relationship"
    token: token!
    token_pk: bigint!
}

"columns and relationships of \"token_registry\""
type token_registry {
    active: Boolean
    address: String!
    beneficiary: String
    fee: Int
    type: token_type
}

"columns and relationships of \"token_tag\""
type token_tag {
    id: bigint!
    "An object relationship"
    tag: tag!
    tag_id: bigint!
    "An object relationship"
    token: token!
    token_pk: bigint!
}

"columns and relationships of \"tzd_domain\""
type tzd_domain {
    expiry: timestamptz
    id: String!
    owner: String
    "An array relationship"
    records(
        "distinct select on columns"
        distinct_on: [tzd_record_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tzd_record_order_by!],
        "filter the rows returned"
        where: tzd_record_bool_exp
    ): [tzd_record!]!
    "An object relationship"
    token: token
    token_pk: bigint
    "An object relationship"
    tzd_tld: tzd_tld!
    tzd_tld_id: String!
}

"columns and relationships of \"tzd_record\""
type tzd_record {
    "An object relationship"
    domain: tzd_domain!
    domain_id: String!
    id: String!
    "An object relationship"
    target: holder!
    target_address: String!
}

"columns and relationships of \"tzd_tld\""
type tzd_tld {
    "An array relationship"
    domains(
        "distinct select on columns"
        distinct_on: [tzd_domain_select_column!],
        "limit the number of rows returned"
        limit: Int,
        "skip the first n rows. Use only with order_by"
        offset: Int,
        "sort the rows by one or more columns"
        order_by: [tzd_domain_order_by!],
        "filter the rows returned"
        where: tzd_domain_bool_exp
    ): [tzd_domain!]!
    id: String!
    owner: String
}

"select columns of table \"attribute\""
enum attribute_select_column {
    "column name"
    id
    "column name"
    name
    "column name"
    type
    "column name"
    value
}

"select columns of table \"currency\""
enum currency_select_column {
    "column name"
    decimals
    "column name"
    fa_contract
    "column name"
    id
    "column name"
    token_pk
    "column name"
    type
}

"ordering argument of a cursor"
enum cursor_ordering {
    "ascending ordering of the cursor"
    ASC
    "descending ordering of the cursor"
    DESC
}

"select columns of table \"dutch_auction_sale\""
enum dutch_auction_sale_select_column {
    "column name"
    amount
    "column name"
    buyer_address
    "column name"
    currency_id
    "column name"
    dutch_auction_id
    "column name"
    id
    "column name"
    level
    "column name"
    marketplace_contract
    "column name"
    ophash
    "column name"
    price
    "column name"
    price_xtz
    "column name"
    seller_address
    "column name"
    sender_address
    "column name"
    timestamp
    "column name"
    token_pk
}

"select columns of table \"dutch_auction\""
enum dutch_auction_select_column {
    "column name"
    amount
    "column name"
    amount_left
    "column name"
    bigmap_key
    "column name"
    currency_id
    "column name"
    end_price
    "column name"
    end_price_xtz
    "column name"
    end_time
    "column name"
    expiry
    "column name"
    fa_contract
    "column name"
    hash
    "column name"
    id
    "column name"
    level
    "column name"
    marketplace_contract
    "column name"
    ophash
    "column name"
    seller_address
    "column name"
    shares
    "column name"
    start_price
    "column name"
    start_price_xtz
    "column name"
    start_time
    "column name"
    status
    "column name"
    timestamp
    "column name"
    token_pk
    "column name"
    update_level
    "column name"
    update_ophash
    "column name"
    update_timestamp
}

"select columns of table \"english_auction_bid\""
enum english_auction_bid_select_column {
    "column name"
    amount
    "column name"
    amount_xtz
    "column name"
    bidder_address
    "column name"
    currency_id
    "column name"
    english_auction_id
    "column name"
    id
    "column name"
    level
    "column name"
    marketplace_contract
    "column name"
    ophash
    "column name"
    timestamp
}

"select columns of table \"english_auction\""
enum english_auction_select_column {
    "column name"
    bigmap_key
    "column name"
    currency_id
    "column name"
    duration
    "column name"
    end_time
    "column name"
    extension_time
    "column name"
    fa_contract
    "column name"
    hash
    "column name"
    highest_bid
    "column name"
    highest_bid_xtz
    "column name"
    highest_bidder_address
    "column name"
    id
    "column name"
    level
    "column name"
    marketplace_contract
    "column name"
    ophash
    "column name"
    price_increment
    "column name"
    price_increment_xtz
    "column name"
    reserve
    "column name"
    reserve_xtz
    "column name"
    seller_address
    "column name"
    shares
    "column name"
    start_time
    "column name"
    status
    "column name"
    timestamp
    "column name"
    token_pk
    "column name"
    update_level
    "column name"
    update_ophash
    "column name"
    update_timestamp
}

"select columns of table \"event\""
enum event_select_column {
    "column name"
    amount
    "column name"
    creator_address
    "column name"
    currency_id
    "column name"
    event_type
    "column name"
    fa_contract
    "column name"
    id
    "column name"
    level
    "column name"
    marketplace_contract
    "column name"
    marketplace_event_type
    "column name"
    marketplace_object_id
    "column name"
    ob_contract
    "column name"
    ophash
    "column name"
    price
    "column name"
    price_xtz
    "column name"
    recipient_address
    "column name"
    reverted
    "column name"
    timestamp
    "column name"
    token_pk
}

"select columns of table \"fa2_attribute_count\""
enum fa2_attribute_count_select_column {
    "column name"
    attribute_id
    "column name"
    editions
    "column name"
    fa_contract
    "column name"
    id
    "column name"
    tokens
}

"select columns of table \"fa\""
enum fa_select_column {
    "column name"
    active_auctions
    "column name"
    active_listing
    "column name"
    category
    "column name"
    collection_id
    "column name"
    collection_type
    "column name"
    contract
    "column name"
    creator_address
    "column name"
    description
    "column name"
    editions
    "column name"
    floor_price
    "column name"
    index_contract_metadata
    "column name"
    items
    "column name"
    last_metadata_update
    "column name"
    ledger_type
    "column name"
    level
    "column name"
    live
    "column name"
    logo
    "column name"
    metadata
    "column name"
    name
    "column name"
    originated
    "column name"
    owners
    "column name"
    path
    "column name"
    short_name
    "column name"
    timestamp
    "column name"
    token_link
    "column name"
    twitter
    "column name"
    type
    "column name"
    tzip16_key
    "column name"
    updated_attributes_counts
    "column name"
    verified_creators
    "column name"
    volume_24h
    "column name"
    volume_total
    "column name"
    website
}

"select columns of table \"gallery_attribute_count\""
enum gallery_attribute_count_select_column {
    "column name"
    attribute_id
    "column name"
    editions
    "column name"
    gallery_pk
    "column name"
    id
    "column name"
    tokens
}

"select columns of table \"holder\""
enum holder_select_column {
    "column name"
    address
    "column name"
    alias
    "column name"
    description
    "column name"
    discord
    "column name"
    dns
    "column name"
    email
    "column name"
    ethereum
    "column name"
    facebook
    "column name"
    flag
    "column name"
    github
    "column name"
    gitlab
    "column name"
    inserted_at
    "column name"
    instagram
    "column name"
    last_metadata_update
    "column name"
    logo
    "column name"
    medium
    "column name"
    reddit
    "column name"
    slack
    "column name"
    support
    "column name"
    telegram
    "column name"
    twitter
    "column name"
    tzdomain
    "column name"
    website
}

"select columns of table \"invitation\""
enum invitation_select_column {
    "column name"
    collaborator_address
    "column name"
    fa_contract
    "column name"
    history
    "column name"
    id
    "column name"
    level
    "column name"
    status
    "column name"
    timestamp
    "column name"
    update_timestamp
}

"select columns of table \"listing_sale\""
enum listing_sale_select_column {
    "column name"
    amount
    "column name"
    buyer_address
    "column name"
    id
    "column name"
    level
    "column name"
    listing_id
    "column name"
    marketplace_contract
    "column name"
    ophash
    "column name"
    price
    "column name"
    price_xtz
    "column name"
    seller_address
    "column name"
    sender_address
    "column name"
    timestamp
    "column name"
    token_pk
}

"select columns of table \"listing\""
enum listing_select_column {
    "column name"
    amount
    "column name"
    amount_left
    "column name"
    bigmap_key
    "column name"
    currency_id
    "column name"
    end_price
    "column name"
    expiry
    "column name"
    fa_contract
    "column name"
    id
    "column name"
    level
    "column name"
    marketplace_contract
    "column name"
    ophash
    "column name"
    price
    "column name"
    price_xtz
    "column name"
    seller_address
    "column name"
    shares
    "column name"
    start_price
    "column name"
    status
    "column name"
    target_address
    "column name"
    timestamp
    "column name"
    token_pk
    "column name"
    update_level
    "column name"
    update_ophash
    "column name"
    update_timestamp
}

"select columns of table \"marketplace_contract\""
enum marketplace_contract_select_column {
    "column name"
    contract
    "column name"
    group
    "column name"
    name
    "column name"
    subgroup
}

"select columns of table \"offer\""
enum offer_select_column {
    "column name"
    bigmap_key
    "column name"
    buyer_address
    "column name"
    collection_offer
    "column name"
    currency_id
    "column name"
    expiry
    "column name"
    fa_contract
    "column name"
    id
    "column name"
    level
    "column name"
    marketplace_contract
    "column name"
    ophash
    "column name"
    price
    "column name"
    price_xtz
    "column name"
    seller_address
    "column name"
    shares
    "column name"
    status
    "column name"
    target_address
    "column name"
    timestamp
    "column name"
    token_pk
    "column name"
    update_level
    "column name"
    update_ophash
    "column name"
    update_timestamp
}

"select columns of table \"open_edition_active\""
enum open_edition_active_select_column {
    "column name"
    airdrop_capacity
    "column name"
    burn_recipe
    "column name"
    end_time
    "column name"
    fa_contract
    "column name"
    level
    "column name"
    max_per_wallet
    "column name"
    ophash
    "column name"
    price
    "column name"
    seller_address
    "column name"
    shares
    "column name"
    shares_total
    "column name"
    start_time
    "column name"
    timestamp
    "column name"
    token_pk
}

"select columns of table \"open_edition\""
enum open_edition_select_column {
    "column name"
    airdrop_capacity
    "column name"
    burn_recipe
    "column name"
    end_time
    "column name"
    fa_contract
    "column name"
    level
    "column name"
    max_per_wallet
    "column name"
    ophash
    "column name"
    price
    "column name"
    seller_address
    "column name"
    shares
    "column name"
    shares_total
    "column name"
    start_time
    "column name"
    timestamp
    "column name"
    token_pk
    "column name"
    valid_royalties
}

"column ordering options"
enum order_by {
    "in ascending order, nulls last"
    asc
    "in ascending order, nulls first"
    asc_nulls_first
    "in ascending order, nulls last"
    asc_nulls_last
    "in descending order, nulls first"
    desc
    "in descending order, nulls first"
    desc_nulls_first
    "in descending order, nulls last"
    desc_nulls_last
}

"select columns of table \"royalties\""
enum royalties_select_column {
    "column name"
    amount
    "column name"
    decimals
    "column name"
    id
    "column name"
    receiver_address
    "column name"
    token_pk
}

"select columns of table \"sales_stat\""
enum sales_stat_select_column {
    "column name"
    id
    "column name"
    interval_days
    "column name"
    rank
    "column name"
    subject_address
    "column name"
    type
    "column name"
    volume
}

"select columns of table \"tag\""
enum tag_select_column {
    "column name"
    id
    "column name"
    name
    "column name"
    token_count
}

"select columns of table \"tezos_storage\""
enum tezos_storage_select_column {
    "column name"
    fa_contract
    "column name"
    id
    "column name"
    tzip16_key
    "column name"
    tzip16_value
}

"select columns of table \"token_attribute\""
enum token_attribute_select_column {
    "column name"
    attribute_id
    "column name"
    id
    "column name"
    token_pk
}

"select columns of table \"token_creator\""
enum token_creator_select_column {
    "column name"
    creator_address
    "column name"
    token_pk
    "column name"
    verified
}

"select columns of table \"token_holder\""
enum token_holder_select_column {
    "column name"
    holder_address
    "column name"
    last_incremented_at
    "column name"
    quantity
    "column name"
    token_pk
}

"select columns of table \"token_operator\""
enum token_operator_select_column {
    "column name"
    allowed
    "column name"
    amount
    "column name"
    id
    "column name"
    operator_address
    "column name"
    owner_address
    "column name"
    token_pk
}

"select columns of table \"token_registry\""
enum token_registry_select_column {
    "column name"
    active
    "column name"
    address
    "column name"
    beneficiary
    "column name"
    fee
    "column name"
    type
}

"select columns of table \"token\""
enum token_select_column {
    "column name"
    artifact_uri
    "column name"
    average
    "column name"
    decimals
    "column name"
    description
    "column name"
    display_uri
    "column name"
    extra
    "column name"
    fa_contract
    "column name"
    flag
    "column name"
    highest_offer
    "column name"
    is_boolean_amount
    "column name"
    last_listed
    "column name"
    last_metadata_update
    "column name"
    level
    "column name"
    lowest_ask
    "column name"
    metadata
    "column name"
    metadata_status
    "column name"
    mime
    "column name"
    name
    "column name"
    ophash
    "column name"
    pk
    "column name"
    rights
    "column name"
    supply
    "column name"
    symbol
    "column name"
    thumbnail_uri
    "column name"
    timestamp
    "column name"
    token_id
    "column name"
    tzip16_key
}

"select columns of table \"token_tag\""
enum token_tag_select_column {
    "column name"
    id
    "column name"
    tag_id
    "column name"
    token_pk
}

"select columns of table \"tzd_domain\""
enum tzd_domain_select_column {
    "column name"
    expiry
    "column name"
    id
    "column name"
    owner
    "column name"
    token_pk
    "column name"
    tzd_tld_id
}

"select columns of table \"tzd_record\""
enum tzd_record_select_column {
    "column name"
    domain_id
    "column name"
    id
    "column name"
    target_address
}

"select columns of table \"tzd_tld\""
enum tzd_tld_select_column {
    "column name"
    id
    "column name"
    owner
}

scalar auction_status

scalar bigint

scalar collection_type

scalar event_type

scalar fa_type

scalar flag_type

scalar invitation_type

scalar jsonb

scalar ledger_type

scalar marketplace_event_type

scalar metadata_status

scalar numeric

scalar sales_stat_type

scalar timestamptz

scalar token_type

"Boolean expression to compare columns of type \"Boolean\". All fields are combined with logical 'AND'."
input Boolean_comparison_exp {
    _eq: Boolean
    _gt: Boolean
    _gte: Boolean
    _in: [Boolean!]
    _is_null: Boolean
    _lt: Boolean
    _lte: Boolean
    _neq: Boolean
    _nin: [Boolean!]
}

"Boolean expression to compare columns of type \"Int\". All fields are combined with logical 'AND'."
input Int_comparison_exp {
    _eq: Int
    _gt: Int
    _gte: Int
    _in: [Int!]
    _is_null: Boolean
    _lt: Int
    _lte: Int
    _neq: Int
    _nin: [Int!]
}

"Boolean expression to compare columns of type \"String\". All fields are combined with logical 'AND'."
input String_comparison_exp {
    _eq: String
    _gt: String
    _gte: String
    "does the column match the given case-insensitive pattern"
    _ilike: String
    _in: [String!]
    "does the column match the given POSIX regular expression, case insensitive"
    _iregex: String
    _is_null: Boolean
    "does the column match the given pattern"
    _like: String
    _lt: String
    _lte: String
    _neq: String
    "does the column NOT match the given case-insensitive pattern"
    _nilike: String
    _nin: [String!]
    "does the column NOT match the given POSIX regular expression, case insensitive"
    _niregex: String
    "does the column NOT match the given pattern"
    _nlike: String
    "does the column NOT match the given POSIX regular expression, case sensitive"
    _nregex: String
    "does the column NOT match the given SQL regular expression"
    _nsimilar: String
    "does the column match the given POSIX regular expression, case sensitive"
    _regex: String
    "does the column match the given SQL regular expression"
    _similar: String
}

"Boolean expression to filter rows from the table \"attribute\". All fields are combined with a logical 'AND'."
input attribute_bool_exp {
    _and: [attribute_bool_exp!]
    _not: attribute_bool_exp
    _or: [attribute_bool_exp!]
    attribute_counts: fa2_attribute_count_bool_exp
    id: bigint_comparison_exp
    name: String_comparison_exp
    tokens: token_attribute_bool_exp
    type: String_comparison_exp
    value: String_comparison_exp
}

"Ordering options when selecting data from \"attribute\"."
input attribute_order_by {
    attribute_counts_aggregate: fa2_attribute_count_aggregate_order_by
    id: order_by
    name: order_by
    tokens_aggregate: token_attribute_aggregate_order_by
    type: order_by
    value: order_by
}

"Streaming cursor of the table \"attribute\""
input attribute_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: attribute_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input attribute_stream_cursor_value_input {
    id: bigint
    name: String
    type: String
    value: String
}

"Boolean expression to compare columns of type \"auction_status\". All fields are combined with logical 'AND'."
input auction_status_comparison_exp {
    _eq: auction_status
    _gt: auction_status
    _gte: auction_status
    _in: [auction_status!]
    _is_null: Boolean
    _lt: auction_status
    _lte: auction_status
    _neq: auction_status
    _nin: [auction_status!]
}

"Boolean expression to compare columns of type \"bigint\". All fields are combined with logical 'AND'."
input bigint_comparison_exp {
    _eq: bigint
    _gt: bigint
    _gte: bigint
    _in: [bigint!]
    _is_null: Boolean
    _lt: bigint
    _lte: bigint
    _neq: bigint
    _nin: [bigint!]
}

"Boolean expression to compare columns of type \"collection_type\". All fields are combined with logical 'AND'."
input collection_type_comparison_exp {
    _eq: collection_type
    _gt: collection_type
    _gte: collection_type
    _in: [collection_type!]
    _is_null: Boolean
    _lt: collection_type
    _lte: collection_type
    _neq: collection_type
    _nin: [collection_type!]
}

"Boolean expression to filter rows from the table \"currency\". All fields are combined with a logical 'AND'."
input currency_bool_exp {
    _and: [currency_bool_exp!]
    _not: currency_bool_exp
    _or: [currency_bool_exp!]
    decimals: Int_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    id: bigint_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
    type: token_type_comparison_exp
}

"Ordering options when selecting data from \"currency\"."
input currency_order_by {
    decimals: order_by
    fa: fa_order_by
    fa_contract: order_by
    id: order_by
    token: token_order_by
    token_pk: order_by
    type: order_by
}

"Streaming cursor of the table \"currency\""
input currency_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: currency_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input currency_stream_cursor_value_input {
    decimals: Int
    fa_contract: String
    id: bigint
    token_pk: bigint
    type: token_type
}

"order by aggregate values of table \"dutch_auction\""
input dutch_auction_aggregate_order_by {
    avg: dutch_auction_avg_order_by
    count: order_by
    max: dutch_auction_max_order_by
    min: dutch_auction_min_order_by
    stddev: dutch_auction_stddev_order_by
    stddev_pop: dutch_auction_stddev_pop_order_by
    stddev_samp: dutch_auction_stddev_samp_order_by
    sum: dutch_auction_sum_order_by
    var_pop: dutch_auction_var_pop_order_by
    var_samp: dutch_auction_var_samp_order_by
    variance: dutch_auction_variance_order_by
}

"order by avg() on columns of table \"dutch_auction\""
input dutch_auction_avg_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    id: order_by
    level: order_by
    start_price: order_by
    start_price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"Boolean expression to filter rows from the table \"dutch_auction\". All fields are combined with a logical 'AND'."
input dutch_auction_bool_exp {
    _and: [dutch_auction_bool_exp!]
    _not: dutch_auction_bool_exp
    _or: [dutch_auction_bool_exp!]
    amount: Int_comparison_exp
    amount_left: Int_comparison_exp
    bigmap_key: bigint_comparison_exp
    currency: currency_bool_exp
    currency_id: bigint_comparison_exp
    end_price: bigint_comparison_exp
    end_price_xtz: bigint_comparison_exp
    end_time: timestamptz_comparison_exp
    expiry: timestamptz_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    hash: String_comparison_exp
    id: bigint_comparison_exp
    level: Int_comparison_exp
    marketplace: marketplace_contract_bool_exp
    marketplace_contract: String_comparison_exp
    ophash: String_comparison_exp
    sales: dutch_auction_sale_bool_exp
    seller: holder_bool_exp
    seller_address: String_comparison_exp
    shares: jsonb_comparison_exp
    start_price: bigint_comparison_exp
    start_price_xtz: bigint_comparison_exp
    start_time: timestamptz_comparison_exp
    status: auction_status_comparison_exp
    timestamp: timestamptz_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
    update_level: Int_comparison_exp
    update_ophash: String_comparison_exp
    update_timestamp: timestamptz_comparison_exp
}

"order by max() on columns of table \"dutch_auction\""
input dutch_auction_max_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    end_time: order_by
    expiry: order_by
    fa_contract: order_by
    hash: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    seller_address: order_by
    start_price: order_by
    start_price_xtz: order_by
    start_time: order_by
    status: order_by
    timestamp: order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"order by min() on columns of table \"dutch_auction\""
input dutch_auction_min_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    end_time: order_by
    expiry: order_by
    fa_contract: order_by
    hash: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    seller_address: order_by
    start_price: order_by
    start_price_xtz: order_by
    start_time: order_by
    status: order_by
    timestamp: order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"Ordering options when selecting data from \"dutch_auction\"."
input dutch_auction_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency: currency_order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    end_time: order_by
    expiry: order_by
    fa: fa_order_by
    fa_contract: order_by
    hash: order_by
    id: order_by
    level: order_by
    marketplace: marketplace_contract_order_by
    marketplace_contract: order_by
    ophash: order_by
    sales_aggregate: dutch_auction_sale_aggregate_order_by
    seller: holder_order_by
    seller_address: order_by
    shares: order_by
    start_price: order_by
    start_price_xtz: order_by
    start_time: order_by
    status: order_by
    timestamp: order_by
    token: token_order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"order by aggregate values of table \"dutch_auction_sale\""
input dutch_auction_sale_aggregate_order_by {
    avg: dutch_auction_sale_avg_order_by
    count: order_by
    max: dutch_auction_sale_max_order_by
    min: dutch_auction_sale_min_order_by
    stddev: dutch_auction_sale_stddev_order_by
    stddev_pop: dutch_auction_sale_stddev_pop_order_by
    stddev_samp: dutch_auction_sale_stddev_samp_order_by
    sum: dutch_auction_sale_sum_order_by
    var_pop: dutch_auction_sale_var_pop_order_by
    var_samp: dutch_auction_sale_var_samp_order_by
    variance: dutch_auction_sale_variance_order_by
}

"order by avg() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_avg_order_by {
    amount: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"dutch_auction_sale\". All fields are combined with a logical 'AND'."
input dutch_auction_sale_bool_exp {
    _and: [dutch_auction_sale_bool_exp!]
    _not: dutch_auction_sale_bool_exp
    _or: [dutch_auction_sale_bool_exp!]
    amount: Int_comparison_exp
    buyer: holder_bool_exp
    buyer_address: String_comparison_exp
    currency: currency_bool_exp
    currency_id: bigint_comparison_exp
    dutch_auction: dutch_auction_bool_exp
    dutch_auction_id: bigint_comparison_exp
    id: bigint_comparison_exp
    level: Int_comparison_exp
    marketplace: marketplace_contract_bool_exp
    marketplace_contract: String_comparison_exp
    ophash: String_comparison_exp
    price: bigint_comparison_exp
    price_xtz: bigint_comparison_exp
    seller: holder_bool_exp
    seller_address: String_comparison_exp
    sender: holder_bool_exp
    sender_address: String_comparison_exp
    timestamp: timestamptz_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
}

"order by max() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_max_order_by {
    amount: order_by
    buyer_address: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller_address: order_by
    sender_address: order_by
    timestamp: order_by
    token_pk: order_by
}

"order by min() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_min_order_by {
    amount: order_by
    buyer_address: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller_address: order_by
    sender_address: order_by
    timestamp: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"dutch_auction_sale\"."
input dutch_auction_sale_order_by {
    amount: order_by
    buyer: holder_order_by
    buyer_address: order_by
    currency: currency_order_by
    currency_id: order_by
    dutch_auction: dutch_auction_order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    marketplace: marketplace_contract_order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller: holder_order_by
    seller_address: order_by
    sender: holder_order_by
    sender_address: order_by
    timestamp: order_by
    token: token_order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_stddev_order_by {
    amount: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_stddev_pop_order_by {
    amount: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_stddev_samp_order_by {
    amount: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"Streaming cursor of the table \"dutch_auction_sale\""
input dutch_auction_sale_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: dutch_auction_sale_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input dutch_auction_sale_stream_cursor_value_input {
    amount: Int
    buyer_address: String
    currency_id: bigint
    dutch_auction_id: bigint
    id: bigint
    level: Int
    marketplace_contract: String
    ophash: String
    price: bigint
    price_xtz: bigint
    seller_address: String
    sender_address: String
    timestamp: timestamptz
    token_pk: bigint
}

"order by sum() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_sum_order_by {
    amount: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by var_pop() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_var_pop_order_by {
    amount: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by var_samp() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_var_samp_order_by {
    amount: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by variance() on columns of table \"dutch_auction_sale\""
input dutch_auction_sale_variance_order_by {
    amount: order_by
    currency_id: order_by
    dutch_auction_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"dutch_auction\""
input dutch_auction_stddev_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    id: order_by
    level: order_by
    start_price: order_by
    start_price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by stddev_pop() on columns of table \"dutch_auction\""
input dutch_auction_stddev_pop_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    id: order_by
    level: order_by
    start_price: order_by
    start_price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by stddev_samp() on columns of table \"dutch_auction\""
input dutch_auction_stddev_samp_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    id: order_by
    level: order_by
    start_price: order_by
    start_price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"Streaming cursor of the table \"dutch_auction\""
input dutch_auction_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: dutch_auction_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input dutch_auction_stream_cursor_value_input {
    amount: Int
    amount_left: Int
    bigmap_key: bigint
    currency_id: bigint
    end_price: bigint
    end_price_xtz: bigint
    end_time: timestamptz
    expiry: timestamptz
    fa_contract: String
    hash: String
    id: bigint
    level: Int
    marketplace_contract: String
    ophash: String
    seller_address: String
    shares: jsonb
    start_price: bigint
    start_price_xtz: bigint
    start_time: timestamptz
    status: auction_status
    timestamp: timestamptz
    token_pk: bigint
    update_level: Int
    update_ophash: String
    update_timestamp: timestamptz
}

"order by sum() on columns of table \"dutch_auction\""
input dutch_auction_sum_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    id: order_by
    level: order_by
    start_price: order_by
    start_price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by var_pop() on columns of table \"dutch_auction\""
input dutch_auction_var_pop_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    id: order_by
    level: order_by
    start_price: order_by
    start_price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by var_samp() on columns of table \"dutch_auction\""
input dutch_auction_var_samp_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    id: order_by
    level: order_by
    start_price: order_by
    start_price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by variance() on columns of table \"dutch_auction\""
input dutch_auction_variance_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    end_price_xtz: order_by
    id: order_by
    level: order_by
    start_price: order_by
    start_price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by aggregate values of table \"english_auction\""
input english_auction_aggregate_order_by {
    avg: english_auction_avg_order_by
    count: order_by
    max: english_auction_max_order_by
    min: english_auction_min_order_by
    stddev: english_auction_stddev_order_by
    stddev_pop: english_auction_stddev_pop_order_by
    stddev_samp: english_auction_stddev_samp_order_by
    sum: english_auction_sum_order_by
    var_pop: english_auction_var_pop_order_by
    var_samp: english_auction_var_samp_order_by
    variance: english_auction_variance_order_by
}

"order by avg() on columns of table \"english_auction\""
input english_auction_avg_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    extension_time: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    id: order_by
    level: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by aggregate values of table \"english_auction_bid\""
input english_auction_bid_aggregate_order_by {
    avg: english_auction_bid_avg_order_by
    count: order_by
    max: english_auction_bid_max_order_by
    min: english_auction_bid_min_order_by
    stddev: english_auction_bid_stddev_order_by
    stddev_pop: english_auction_bid_stddev_pop_order_by
    stddev_samp: english_auction_bid_stddev_samp_order_by
    sum: english_auction_bid_sum_order_by
    var_pop: english_auction_bid_var_pop_order_by
    var_samp: english_auction_bid_var_samp_order_by
    variance: english_auction_bid_variance_order_by
}

"order by avg() on columns of table \"english_auction_bid\""
input english_auction_bid_avg_order_by {
    amount: order_by
    amount_xtz: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
}

"Boolean expression to filter rows from the table \"english_auction_bid\". All fields are combined with a logical 'AND'."
input english_auction_bid_bool_exp {
    _and: [english_auction_bid_bool_exp!]
    _not: english_auction_bid_bool_exp
    _or: [english_auction_bid_bool_exp!]
    amount: bigint_comparison_exp
    amount_xtz: bigint_comparison_exp
    auction: english_auction_bool_exp
    bidder: holder_bool_exp
    bidder_address: String_comparison_exp
    currency: currency_bool_exp
    currency_id: bigint_comparison_exp
    english_auction_id: bigint_comparison_exp
    id: bigint_comparison_exp
    level: Int_comparison_exp
    marketplace: marketplace_contract_bool_exp
    marketplace_contract: String_comparison_exp
    ophash: String_comparison_exp
    timestamp: timestamptz_comparison_exp
}

"order by max() on columns of table \"english_auction_bid\""
input english_auction_bid_max_order_by {
    amount: order_by
    amount_xtz: order_by
    bidder_address: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    timestamp: order_by
}

"order by min() on columns of table \"english_auction_bid\""
input english_auction_bid_min_order_by {
    amount: order_by
    amount_xtz: order_by
    bidder_address: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    timestamp: order_by
}

"Ordering options when selecting data from \"english_auction_bid\"."
input english_auction_bid_order_by {
    amount: order_by
    amount_xtz: order_by
    auction: english_auction_order_by
    bidder: holder_order_by
    bidder_address: order_by
    currency: currency_order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
    marketplace: marketplace_contract_order_by
    marketplace_contract: order_by
    ophash: order_by
    timestamp: order_by
}

"order by stddev() on columns of table \"english_auction_bid\""
input english_auction_bid_stddev_order_by {
    amount: order_by
    amount_xtz: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
}

"order by stddev_pop() on columns of table \"english_auction_bid\""
input english_auction_bid_stddev_pop_order_by {
    amount: order_by
    amount_xtz: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
}

"order by stddev_samp() on columns of table \"english_auction_bid\""
input english_auction_bid_stddev_samp_order_by {
    amount: order_by
    amount_xtz: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
}

"Streaming cursor of the table \"english_auction_bid\""
input english_auction_bid_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: english_auction_bid_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input english_auction_bid_stream_cursor_value_input {
    amount: bigint
    amount_xtz: bigint
    bidder_address: String
    currency_id: bigint
    english_auction_id: bigint
    id: bigint
    level: Int
    marketplace_contract: String
    ophash: String
    timestamp: timestamptz
}

"order by sum() on columns of table \"english_auction_bid\""
input english_auction_bid_sum_order_by {
    amount: order_by
    amount_xtz: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
}

"order by var_pop() on columns of table \"english_auction_bid\""
input english_auction_bid_var_pop_order_by {
    amount: order_by
    amount_xtz: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
}

"order by var_samp() on columns of table \"english_auction_bid\""
input english_auction_bid_var_samp_order_by {
    amount: order_by
    amount_xtz: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
}

"order by variance() on columns of table \"english_auction_bid\""
input english_auction_bid_variance_order_by {
    amount: order_by
    amount_xtz: order_by
    currency_id: order_by
    english_auction_id: order_by
    id: order_by
    level: order_by
}

"Boolean expression to filter rows from the table \"english_auction\". All fields are combined with a logical 'AND'."
input english_auction_bool_exp {
    _and: [english_auction_bool_exp!]
    _not: english_auction_bool_exp
    _or: [english_auction_bool_exp!]
    bids: english_auction_bid_bool_exp
    bigmap_key: bigint_comparison_exp
    currency: currency_bool_exp
    currency_id: bigint_comparison_exp
    duration: Int_comparison_exp
    end_time: timestamptz_comparison_exp
    extension_time: Int_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    hash: String_comparison_exp
    highest_bid: bigint_comparison_exp
    highest_bid_xtz: bigint_comparison_exp
    highest_bidder: holder_bool_exp
    highest_bidder_address: String_comparison_exp
    id: bigint_comparison_exp
    level: Int_comparison_exp
    marketplace: marketplace_contract_bool_exp
    marketplace_contract: String_comparison_exp
    ophash: String_comparison_exp
    price_increment: bigint_comparison_exp
    price_increment_xtz: bigint_comparison_exp
    reserve: bigint_comparison_exp
    reserve_xtz: bigint_comparison_exp
    seller: holder_bool_exp
    seller_address: String_comparison_exp
    shares: jsonb_comparison_exp
    start_time: timestamptz_comparison_exp
    status: auction_status_comparison_exp
    timestamp: timestamptz_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
    update_level: Int_comparison_exp
    update_ophash: String_comparison_exp
    update_timestamp: timestamptz_comparison_exp
}

"order by max() on columns of table \"english_auction\""
input english_auction_max_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    end_time: order_by
    extension_time: order_by
    fa_contract: order_by
    hash: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    highest_bidder_address: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    seller_address: order_by
    start_time: order_by
    status: order_by
    timestamp: order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"order by min() on columns of table \"english_auction\""
input english_auction_min_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    end_time: order_by
    extension_time: order_by
    fa_contract: order_by
    hash: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    highest_bidder_address: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    seller_address: order_by
    start_time: order_by
    status: order_by
    timestamp: order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"Ordering options when selecting data from \"english_auction\"."
input english_auction_order_by {
    bids_aggregate: english_auction_bid_aggregate_order_by
    bigmap_key: order_by
    currency: currency_order_by
    currency_id: order_by
    duration: order_by
    end_time: order_by
    extension_time: order_by
    fa: fa_order_by
    fa_contract: order_by
    hash: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    highest_bidder: holder_order_by
    highest_bidder_address: order_by
    id: order_by
    level: order_by
    marketplace: marketplace_contract_order_by
    marketplace_contract: order_by
    ophash: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    seller: holder_order_by
    seller_address: order_by
    shares: order_by
    start_time: order_by
    status: order_by
    timestamp: order_by
    token: token_order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"order by stddev() on columns of table \"english_auction\""
input english_auction_stddev_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    extension_time: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    id: order_by
    level: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by stddev_pop() on columns of table \"english_auction\""
input english_auction_stddev_pop_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    extension_time: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    id: order_by
    level: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by stddev_samp() on columns of table \"english_auction\""
input english_auction_stddev_samp_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    extension_time: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    id: order_by
    level: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"Streaming cursor of the table \"english_auction\""
input english_auction_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: english_auction_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input english_auction_stream_cursor_value_input {
    bigmap_key: bigint
    currency_id: bigint
    duration: Int
    end_time: timestamptz
    extension_time: Int
    fa_contract: String
    hash: String
    highest_bid: bigint
    highest_bid_xtz: bigint
    highest_bidder_address: String
    id: bigint
    level: Int
    marketplace_contract: String
    ophash: String
    price_increment: bigint
    price_increment_xtz: bigint
    reserve: bigint
    reserve_xtz: bigint
    seller_address: String
    shares: jsonb
    start_time: timestamptz
    status: auction_status
    timestamp: timestamptz
    token_pk: bigint
    update_level: Int
    update_ophash: String
    update_timestamp: timestamptz
}

"order by sum() on columns of table \"english_auction\""
input english_auction_sum_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    extension_time: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    id: order_by
    level: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by var_pop() on columns of table \"english_auction\""
input english_auction_var_pop_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    extension_time: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    id: order_by
    level: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by var_samp() on columns of table \"english_auction\""
input english_auction_var_samp_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    extension_time: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    id: order_by
    level: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by variance() on columns of table \"english_auction\""
input english_auction_variance_order_by {
    bigmap_key: order_by
    currency_id: order_by
    duration: order_by
    extension_time: order_by
    highest_bid: order_by
    highest_bid_xtz: order_by
    id: order_by
    level: order_by
    price_increment: order_by
    price_increment_xtz: order_by
    reserve: order_by
    reserve_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by aggregate values of table \"event\""
input event_aggregate_order_by {
    avg: event_avg_order_by
    count: order_by
    max: event_max_order_by
    min: event_min_order_by
    stddev: event_stddev_order_by
    stddev_pop: event_stddev_pop_order_by
    stddev_samp: event_stddev_samp_order_by
    sum: event_sum_order_by
    var_pop: event_var_pop_order_by
    var_samp: event_var_samp_order_by
    variance: event_variance_order_by
}

"order by avg() on columns of table \"event\""
input event_avg_order_by {
    amount: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    marketplace_object_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"event\". All fields are combined with a logical 'AND'."
input event_bool_exp {
    _and: [event_bool_exp!]
    _not: event_bool_exp
    _or: [event_bool_exp!]
    amount: bigint_comparison_exp
    creator: holder_bool_exp
    creator_address: String_comparison_exp
    currency: currency_bool_exp
    currency_id: bigint_comparison_exp
    event_type: event_type_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    id: bigint_comparison_exp
    level: Int_comparison_exp
    marketplace: marketplace_contract_bool_exp
    marketplace_contract: String_comparison_exp
    marketplace_event_type: marketplace_event_type_comparison_exp
    marketplace_object_id: bigint_comparison_exp
    ob_contract: Boolean_comparison_exp
    ophash: String_comparison_exp
    price: bigint_comparison_exp
    price_xtz: bigint_comparison_exp
    recipient: holder_bool_exp
    recipient_address: String_comparison_exp
    reverted: Boolean_comparison_exp
    timestamp: timestamptz_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
}

"order by max() on columns of table \"event\""
input event_max_order_by {
    amount: order_by
    creator_address: order_by
    currency_id: order_by
    event_type: order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    marketplace_event_type: order_by
    marketplace_object_id: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    recipient_address: order_by
    timestamp: order_by
    token_pk: order_by
}

"order by min() on columns of table \"event\""
input event_min_order_by {
    amount: order_by
    creator_address: order_by
    currency_id: order_by
    event_type: order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    marketplace_event_type: order_by
    marketplace_object_id: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    recipient_address: order_by
    timestamp: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"event\"."
input event_order_by {
    amount: order_by
    creator: holder_order_by
    creator_address: order_by
    currency: currency_order_by
    currency_id: order_by
    event_type: order_by
    fa: fa_order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    marketplace: marketplace_contract_order_by
    marketplace_contract: order_by
    marketplace_event_type: order_by
    marketplace_object_id: order_by
    ob_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    recipient: holder_order_by
    recipient_address: order_by
    reverted: order_by
    timestamp: order_by
    token: token_order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"event\""
input event_stddev_order_by {
    amount: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    marketplace_object_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"event\""
input event_stddev_pop_order_by {
    amount: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    marketplace_object_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"event\""
input event_stddev_samp_order_by {
    amount: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    marketplace_object_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"Streaming cursor of the table \"event\""
input event_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: event_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input event_stream_cursor_value_input {
    amount: bigint
    creator_address: String
    currency_id: bigint
    event_type: event_type
    fa_contract: String
    id: bigint
    level: Int
    marketplace_contract: String
    marketplace_event_type: marketplace_event_type
    marketplace_object_id: bigint
    ob_contract: Boolean
    ophash: String
    price: bigint
    price_xtz: bigint
    recipient_address: String
    reverted: Boolean
    timestamp: timestamptz
    token_pk: bigint
}

"order by sum() on columns of table \"event\""
input event_sum_order_by {
    amount: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    marketplace_object_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"Boolean expression to compare columns of type \"event_type\". All fields are combined with logical 'AND'."
input event_type_comparison_exp {
    _eq: event_type
    _gt: event_type
    _gte: event_type
    _in: [event_type!]
    _is_null: Boolean
    _lt: event_type
    _lte: event_type
    _neq: event_type
    _nin: [event_type!]
}

"order by var_pop() on columns of table \"event\""
input event_var_pop_order_by {
    amount: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    marketplace_object_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by var_samp() on columns of table \"event\""
input event_var_samp_order_by {
    amount: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    marketplace_object_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by variance() on columns of table \"event\""
input event_variance_order_by {
    amount: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    marketplace_object_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by aggregate values of table \"fa2_attribute_count\""
input fa2_attribute_count_aggregate_order_by {
    avg: fa2_attribute_count_avg_order_by
    count: order_by
    max: fa2_attribute_count_max_order_by
    min: fa2_attribute_count_min_order_by
    stddev: fa2_attribute_count_stddev_order_by
    stddev_pop: fa2_attribute_count_stddev_pop_order_by
    stddev_samp: fa2_attribute_count_stddev_samp_order_by
    sum: fa2_attribute_count_sum_order_by
    var_pop: fa2_attribute_count_var_pop_order_by
    var_samp: fa2_attribute_count_var_samp_order_by
    variance: fa2_attribute_count_variance_order_by
}

"order by avg() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_avg_order_by {
    attribute_id: order_by
    editions: order_by
    id: order_by
    tokens: order_by
}

"Boolean expression to filter rows from the table \"fa2_attribute_count\". All fields are combined with a logical 'AND'."
input fa2_attribute_count_bool_exp {
    _and: [fa2_attribute_count_bool_exp!]
    _not: fa2_attribute_count_bool_exp
    _or: [fa2_attribute_count_bool_exp!]
    attribute: attribute_bool_exp
    attribute_id: bigint_comparison_exp
    editions: bigint_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    id: bigint_comparison_exp
    tokens: bigint_comparison_exp
}

"order by max() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_max_order_by {
    attribute_id: order_by
    editions: order_by
    fa_contract: order_by
    id: order_by
    tokens: order_by
}

"order by min() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_min_order_by {
    attribute_id: order_by
    editions: order_by
    fa_contract: order_by
    id: order_by
    tokens: order_by
}

"Ordering options when selecting data from \"fa2_attribute_count\"."
input fa2_attribute_count_order_by {
    attribute: attribute_order_by
    attribute_id: order_by
    editions: order_by
    fa: fa_order_by
    fa_contract: order_by
    id: order_by
    tokens: order_by
}

"order by stddev() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_stddev_order_by {
    attribute_id: order_by
    editions: order_by
    id: order_by
    tokens: order_by
}

"order by stddev_pop() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_stddev_pop_order_by {
    attribute_id: order_by
    editions: order_by
    id: order_by
    tokens: order_by
}

"order by stddev_samp() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_stddev_samp_order_by {
    attribute_id: order_by
    editions: order_by
    id: order_by
    tokens: order_by
}

"Streaming cursor of the table \"fa2_attribute_count\""
input fa2_attribute_count_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: fa2_attribute_count_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input fa2_attribute_count_stream_cursor_value_input {
    attribute_id: bigint
    editions: bigint
    fa_contract: String
    id: bigint
    tokens: bigint
}

"order by sum() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_sum_order_by {
    attribute_id: order_by
    editions: order_by
    id: order_by
    tokens: order_by
}

"order by var_pop() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_var_pop_order_by {
    attribute_id: order_by
    editions: order_by
    id: order_by
    tokens: order_by
}

"order by var_samp() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_var_samp_order_by {
    attribute_id: order_by
    editions: order_by
    id: order_by
    tokens: order_by
}

"order by variance() on columns of table \"fa2_attribute_count\""
input fa2_attribute_count_variance_order_by {
    attribute_id: order_by
    editions: order_by
    id: order_by
    tokens: order_by
}

"order by aggregate values of table \"fa\""
input fa_aggregate_order_by {
    avg: fa_avg_order_by
    count: order_by
    max: fa_max_order_by
    min: fa_min_order_by
    stddev: fa_stddev_order_by
    stddev_pop: fa_stddev_pop_order_by
    stddev_samp: fa_stddev_samp_order_by
    sum: fa_sum_order_by
    var_pop: fa_var_pop_order_by
    var_samp: fa_var_samp_order_by
    variance: fa_variance_order_by
}

"order by avg() on columns of table \"fa\""
input fa_avg_order_by {
    active_auctions: order_by
    active_listing: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    level: order_by
    owners: order_by
    volume_24h: order_by
    volume_total: order_by
}

"Boolean expression to filter rows from the table \"fa\". All fields are combined with a logical 'AND'."
input fa_bool_exp {
    _and: [fa_bool_exp!]
    _not: fa_bool_exp
    _or: [fa_bool_exp!]
    active_auctions: Int_comparison_exp
    active_listing: Int_comparison_exp
    attribute_counts: fa2_attribute_count_bool_exp
    category: String_comparison_exp
    collaborators: invitation_bool_exp
    collection_id: String_comparison_exp
    collection_type: collection_type_comparison_exp
    contract: String_comparison_exp
    creator: holder_bool_exp
    creator_address: String_comparison_exp
    description: String_comparison_exp
    dutch_auctions: dutch_auction_bool_exp
    editions: bigint_comparison_exp
    english_auctions: english_auction_bool_exp
    events: event_bool_exp
    floor_price: bigint_comparison_exp
    index_contract_metadata: Boolean_comparison_exp
    items: Int_comparison_exp
    last_metadata_update: timestamptz_comparison_exp
    ledger_type: ledger_type_comparison_exp
    level: Int_comparison_exp
    listings: listing_bool_exp
    live: Boolean_comparison_exp
    logo: String_comparison_exp
    metadata: String_comparison_exp
    name: String_comparison_exp
    offers: offer_bool_exp
    open_edition: open_edition_bool_exp
    originated: String_comparison_exp
    owners: Int_comparison_exp
    path: String_comparison_exp
    short_name: String_comparison_exp
    timestamp: timestamptz_comparison_exp
    token_link: String_comparison_exp
    tokens: token_bool_exp
    twitter: String_comparison_exp
    type: fa_type_comparison_exp
    tzip16_key: String_comparison_exp
    updated_attributes_counts: timestamptz_comparison_exp
    verified_creators: jsonb_comparison_exp
    volume_24h: bigint_comparison_exp
    volume_total: bigint_comparison_exp
    website: String_comparison_exp
}

"order by max() on columns of table \"fa\""
input fa_max_order_by {
    active_auctions: order_by
    active_listing: order_by
    category: order_by
    collection_id: order_by
    collection_type: order_by
    contract: order_by
    creator_address: order_by
    description: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    last_metadata_update: order_by
    ledger_type: order_by
    level: order_by
    logo: order_by
    metadata: order_by
    name: order_by
    originated: order_by
    owners: order_by
    path: order_by
    short_name: order_by
    timestamp: order_by
    token_link: order_by
    twitter: order_by
    type: order_by
    tzip16_key: order_by
    updated_attributes_counts: order_by
    volume_24h: order_by
    volume_total: order_by
    website: order_by
}

"order by min() on columns of table \"fa\""
input fa_min_order_by {
    active_auctions: order_by
    active_listing: order_by
    category: order_by
    collection_id: order_by
    collection_type: order_by
    contract: order_by
    creator_address: order_by
    description: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    last_metadata_update: order_by
    ledger_type: order_by
    level: order_by
    logo: order_by
    metadata: order_by
    name: order_by
    originated: order_by
    owners: order_by
    path: order_by
    short_name: order_by
    timestamp: order_by
    token_link: order_by
    twitter: order_by
    type: order_by
    tzip16_key: order_by
    updated_attributes_counts: order_by
    volume_24h: order_by
    volume_total: order_by
    website: order_by
}

"Ordering options when selecting data from \"fa\"."
input fa_order_by {
    active_auctions: order_by
    active_listing: order_by
    attribute_counts_aggregate: fa2_attribute_count_aggregate_order_by
    category: order_by
    collaborators_aggregate: invitation_aggregate_order_by
    collection_id: order_by
    collection_type: order_by
    contract: order_by
    creator: holder_order_by
    creator_address: order_by
    description: order_by
    dutch_auctions_aggregate: dutch_auction_aggregate_order_by
    editions: order_by
    english_auctions_aggregate: english_auction_aggregate_order_by
    events_aggregate: event_aggregate_order_by
    floor_price: order_by
    index_contract_metadata: order_by
    items: order_by
    last_metadata_update: order_by
    ledger_type: order_by
    level: order_by
    listings_aggregate: listing_aggregate_order_by
    live: order_by
    logo: order_by
    metadata: order_by
    name: order_by
    offers_aggregate: offer_aggregate_order_by
    open_edition_aggregate: open_edition_aggregate_order_by
    originated: order_by
    owners: order_by
    path: order_by
    short_name: order_by
    timestamp: order_by
    token_link: order_by
    tokens_aggregate: token_aggregate_order_by
    twitter: order_by
    type: order_by
    tzip16_key: order_by
    updated_attributes_counts: order_by
    verified_creators: order_by
    volume_24h: order_by
    volume_total: order_by
    website: order_by
}

"order by stddev() on columns of table \"fa\""
input fa_stddev_order_by {
    active_auctions: order_by
    active_listing: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    level: order_by
    owners: order_by
    volume_24h: order_by
    volume_total: order_by
}

"order by stddev_pop() on columns of table \"fa\""
input fa_stddev_pop_order_by {
    active_auctions: order_by
    active_listing: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    level: order_by
    owners: order_by
    volume_24h: order_by
    volume_total: order_by
}

"order by stddev_samp() on columns of table \"fa\""
input fa_stddev_samp_order_by {
    active_auctions: order_by
    active_listing: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    level: order_by
    owners: order_by
    volume_24h: order_by
    volume_total: order_by
}

"Streaming cursor of the table \"fa\""
input fa_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: fa_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input fa_stream_cursor_value_input {
    active_auctions: Int
    active_listing: Int
    category: String
    collection_id: String
    collection_type: collection_type
    contract: String
    creator_address: String
    description: String
    editions: bigint
    floor_price: bigint
    index_contract_metadata: Boolean
    items: Int
    last_metadata_update: timestamptz
    ledger_type: ledger_type
    level: Int
    live: Boolean
    logo: String
    metadata: String
    name: String
    originated: String
    owners: Int
    path: String
    short_name: String
    timestamp: timestamptz
    token_link: String
    twitter: String
    type: fa_type
    tzip16_key: String
    updated_attributes_counts: timestamptz
    verified_creators: jsonb
    volume_24h: bigint
    volume_total: bigint
    website: String
}

"order by sum() on columns of table \"fa\""
input fa_sum_order_by {
    active_auctions: order_by
    active_listing: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    level: order_by
    owners: order_by
    volume_24h: order_by
    volume_total: order_by
}

"Boolean expression to compare columns of type \"fa_type\". All fields are combined with logical 'AND'."
input fa_type_comparison_exp {
    _eq: fa_type
    _gt: fa_type
    _gte: fa_type
    _in: [fa_type!]
    _is_null: Boolean
    _lt: fa_type
    _lte: fa_type
    _neq: fa_type
    _nin: [fa_type!]
}

"order by var_pop() on columns of table \"fa\""
input fa_var_pop_order_by {
    active_auctions: order_by
    active_listing: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    level: order_by
    owners: order_by
    volume_24h: order_by
    volume_total: order_by
}

"order by var_samp() on columns of table \"fa\""
input fa_var_samp_order_by {
    active_auctions: order_by
    active_listing: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    level: order_by
    owners: order_by
    volume_24h: order_by
    volume_total: order_by
}

"order by variance() on columns of table \"fa\""
input fa_variance_order_by {
    active_auctions: order_by
    active_listing: order_by
    editions: order_by
    floor_price: order_by
    items: order_by
    level: order_by
    owners: order_by
    volume_24h: order_by
    volume_total: order_by
}

"Boolean expression to compare columns of type \"flag_type\". All fields are combined with logical 'AND'."
input flag_type_comparison_exp {
    _eq: flag_type
    _gt: flag_type
    _gte: flag_type
    _in: [flag_type!]
    _is_null: Boolean
    _lt: flag_type
    _lte: flag_type
    _neq: flag_type
    _nin: [flag_type!]
}

"Boolean expression to filter rows from the table \"gallery_attribute_count\". All fields are combined with a logical 'AND'."
input gallery_attribute_count_bool_exp {
    _and: [gallery_attribute_count_bool_exp!]
    _not: gallery_attribute_count_bool_exp
    _or: [gallery_attribute_count_bool_exp!]
    attribute: attribute_bool_exp
    attribute_id: bigint_comparison_exp
    editions: bigint_comparison_exp
    gallery_pk: bigint_comparison_exp
    id: bigint_comparison_exp
    tokens: bigint_comparison_exp
}

"Ordering options when selecting data from \"gallery_attribute_count\"."
input gallery_attribute_count_order_by {
    attribute: attribute_order_by
    attribute_id: order_by
    editions: order_by
    gallery_pk: order_by
    id: order_by
    tokens: order_by
}

"Streaming cursor of the table \"gallery_attribute_count\""
input gallery_attribute_count_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: gallery_attribute_count_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input gallery_attribute_count_stream_cursor_value_input {
    attribute_id: bigint
    editions: bigint
    gallery_pk: bigint
    id: bigint
    tokens: bigint
}

"Boolean expression to filter rows from the table \"holder\". All fields are combined with a logical 'AND'."
input holder_bool_exp {
    _and: [holder_bool_exp!]
    _not: holder_bool_exp
    _or: [holder_bool_exp!]
    address: String_comparison_exp
    alias: String_comparison_exp
    collaborations: invitation_bool_exp
    created_tokens: token_creator_bool_exp
    description: String_comparison_exp
    discord: String_comparison_exp
    dns: String_comparison_exp
    dutch_auctions_bought: dutch_auction_sale_bool_exp
    dutch_auctions_created: dutch_auction_bool_exp
    dutch_auctions_sold: dutch_auction_sale_bool_exp
    email: String_comparison_exp
    english_auction_bids: english_auction_bid_bool_exp
    english_auctions_created: english_auction_bool_exp
    english_auctions_highest_bidder: english_auction_bool_exp
    ethereum: String_comparison_exp
    events_creator: event_bool_exp
    events_recipient: event_bool_exp
    fa2s_created: fa_bool_exp
    facebook: String_comparison_exp
    flag: flag_type_comparison_exp
    github: String_comparison_exp
    gitlab: String_comparison_exp
    held_tokens: token_holder_bool_exp
    inserted_at: timestamptz_comparison_exp
    instagram: String_comparison_exp
    last_metadata_update: timestamptz_comparison_exp
    listings_bought: listing_sale_bool_exp
    listings_created: listing_bool_exp
    listings_sold: listing_sale_bool_exp
    logo: String_comparison_exp
    medium: String_comparison_exp
    offers_accepted: offer_bool_exp
    offers_created: offer_bool_exp
    open_edition_created: open_edition_bool_exp
    operator_operators: token_operator_bool_exp
    owner_operators: token_operator_bool_exp
    receiver_royalties: royalties_bool_exp
    reddit: String_comparison_exp
    sales_stats: sales_stat_bool_exp
    slack: String_comparison_exp
    support: String_comparison_exp
    telegram: String_comparison_exp
    twitter: String_comparison_exp
    tzdomain: String_comparison_exp
    website: String_comparison_exp
}

"Ordering options when selecting data from \"holder\"."
input holder_order_by {
    address: order_by
    alias: order_by
    collaborations_aggregate: invitation_aggregate_order_by
    created_tokens_aggregate: token_creator_aggregate_order_by
    description: order_by
    discord: order_by
    dns: order_by
    dutch_auctions_bought_aggregate: dutch_auction_sale_aggregate_order_by
    dutch_auctions_created_aggregate: dutch_auction_aggregate_order_by
    dutch_auctions_sold_aggregate: dutch_auction_sale_aggregate_order_by
    email: order_by
    english_auction_bids_aggregate: english_auction_bid_aggregate_order_by
    english_auctions_created_aggregate: english_auction_aggregate_order_by
    english_auctions_highest_bidder_aggregate: english_auction_aggregate_order_by
    ethereum: order_by
    events_creator_aggregate: event_aggregate_order_by
    events_recipient_aggregate: event_aggregate_order_by
    fa2s_created_aggregate: fa_aggregate_order_by
    facebook: order_by
    flag: order_by
    github: order_by
    gitlab: order_by
    held_tokens_aggregate: token_holder_aggregate_order_by
    inserted_at: order_by
    instagram: order_by
    last_metadata_update: order_by
    listings_bought_aggregate: listing_sale_aggregate_order_by
    listings_created_aggregate: listing_aggregate_order_by
    listings_sold_aggregate: listing_sale_aggregate_order_by
    logo: order_by
    medium: order_by
    offers_accepted_aggregate: offer_aggregate_order_by
    offers_created_aggregate: offer_aggregate_order_by
    open_edition_created_aggregate: open_edition_aggregate_order_by
    operator_operators_aggregate: token_operator_aggregate_order_by
    owner_operators_aggregate: token_operator_aggregate_order_by
    receiver_royalties_aggregate: royalties_aggregate_order_by
    reddit: order_by
    sales_stats_aggregate: sales_stat_aggregate_order_by
    slack: order_by
    support: order_by
    telegram: order_by
    twitter: order_by
    tzdomain: order_by
    website: order_by
}

"Streaming cursor of the table \"holder\""
input holder_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: holder_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input holder_stream_cursor_value_input {
    address: String
    alias: String
    description: String
    discord: String
    dns: String
    email: String
    ethereum: String
    facebook: String
    flag: flag_type
    github: String
    gitlab: String
    inserted_at: timestamptz
    instagram: String
    last_metadata_update: timestamptz
    logo: String
    medium: String
    reddit: String
    slack: String
    support: String
    telegram: String
    twitter: String
    tzdomain: String
    website: String
}

"order by aggregate values of table \"invitation\""
input invitation_aggregate_order_by {
    avg: invitation_avg_order_by
    count: order_by
    max: invitation_max_order_by
    min: invitation_min_order_by
    stddev: invitation_stddev_order_by
    stddev_pop: invitation_stddev_pop_order_by
    stddev_samp: invitation_stddev_samp_order_by
    sum: invitation_sum_order_by
    var_pop: invitation_var_pop_order_by
    var_samp: invitation_var_samp_order_by
    variance: invitation_variance_order_by
}

"order by avg() on columns of table \"invitation\""
input invitation_avg_order_by {
    id: order_by
    level: order_by
}

"Boolean expression to filter rows from the table \"invitation\". All fields are combined with a logical 'AND'."
input invitation_bool_exp {
    _and: [invitation_bool_exp!]
    _not: invitation_bool_exp
    _or: [invitation_bool_exp!]
    collaborator_address: String_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    history: jsonb_comparison_exp
    holder: holder_bool_exp
    id: bigint_comparison_exp
    level: Int_comparison_exp
    status: invitation_type_comparison_exp
    timestamp: timestamptz_comparison_exp
    update_timestamp: timestamptz_comparison_exp
}

"order by max() on columns of table \"invitation\""
input invitation_max_order_by {
    collaborator_address: order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    status: order_by
    timestamp: order_by
    update_timestamp: order_by
}

"order by min() on columns of table \"invitation\""
input invitation_min_order_by {
    collaborator_address: order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    status: order_by
    timestamp: order_by
    update_timestamp: order_by
}

"Ordering options when selecting data from \"invitation\"."
input invitation_order_by {
    collaborator_address: order_by
    fa: fa_order_by
    fa_contract: order_by
    history: order_by
    holder: holder_order_by
    id: order_by
    level: order_by
    status: order_by
    timestamp: order_by
    update_timestamp: order_by
}

"order by stddev() on columns of table \"invitation\""
input invitation_stddev_order_by {
    id: order_by
    level: order_by
}

"order by stddev_pop() on columns of table \"invitation\""
input invitation_stddev_pop_order_by {
    id: order_by
    level: order_by
}

"order by stddev_samp() on columns of table \"invitation\""
input invitation_stddev_samp_order_by {
    id: order_by
    level: order_by
}

"Streaming cursor of the table \"invitation\""
input invitation_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: invitation_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input invitation_stream_cursor_value_input {
    collaborator_address: String
    fa_contract: String
    history: jsonb
    id: bigint
    level: Int
    status: invitation_type
    timestamp: timestamptz
    update_timestamp: timestamptz
}

"order by sum() on columns of table \"invitation\""
input invitation_sum_order_by {
    id: order_by
    level: order_by
}

"Boolean expression to compare columns of type \"invitation_type\". All fields are combined with logical 'AND'."
input invitation_type_comparison_exp {
    _eq: invitation_type
    _gt: invitation_type
    _gte: invitation_type
    _in: [invitation_type!]
    _is_null: Boolean
    _lt: invitation_type
    _lte: invitation_type
    _neq: invitation_type
    _nin: [invitation_type!]
}

"order by var_pop() on columns of table \"invitation\""
input invitation_var_pop_order_by {
    id: order_by
    level: order_by
}

"order by var_samp() on columns of table \"invitation\""
input invitation_var_samp_order_by {
    id: order_by
    level: order_by
}

"order by variance() on columns of table \"invitation\""
input invitation_variance_order_by {
    id: order_by
    level: order_by
}

input jsonb_cast_exp {
    String: String_comparison_exp
}

"Boolean expression to compare columns of type \"jsonb\". All fields are combined with logical 'AND'."
input jsonb_comparison_exp {
    _cast: jsonb_cast_exp
    "is the column contained in the given json value"
    _contained_in: jsonb
    "does the column contain the given json value at the top level"
    _contains: jsonb
    _eq: jsonb
    _gt: jsonb
    _gte: jsonb
    "does the string exist as a top-level key in the column"
    _has_key: String
    "do all of these strings exist as top-level keys in the column"
    _has_keys_all: [String!]
    "do any of these strings exist as top-level keys in the column"
    _has_keys_any: [String!]
    _in: [jsonb!]
    _is_null: Boolean
    _lt: jsonb
    _lte: jsonb
    _neq: jsonb
    _nin: [jsonb!]
}

"Boolean expression to compare columns of type \"ledger_type\". All fields are combined with logical 'AND'."
input ledger_type_comparison_exp {
    _eq: ledger_type
    _gt: ledger_type
    _gte: ledger_type
    _in: [ledger_type!]
    _is_null: Boolean
    _lt: ledger_type
    _lte: ledger_type
    _neq: ledger_type
    _nin: [ledger_type!]
}

"order by aggregate values of table \"listing\""
input listing_aggregate_order_by {
    avg: listing_avg_order_by
    count: order_by
    max: listing_max_order_by
    min: listing_min_order_by
    stddev: listing_stddev_order_by
    stddev_pop: listing_stddev_pop_order_by
    stddev_samp: listing_stddev_samp_order_by
    sum: listing_sum_order_by
    var_pop: listing_var_pop_order_by
    var_samp: listing_var_samp_order_by
    variance: listing_variance_order_by
}

"order by avg() on columns of table \"listing\""
input listing_avg_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    start_price: order_by
    token_pk: order_by
    update_level: order_by
}

"Boolean expression to filter rows from the table \"listing\". All fields are combined with a logical 'AND'."
input listing_bool_exp {
    _and: [listing_bool_exp!]
    _not: listing_bool_exp
    _or: [listing_bool_exp!]
    amount: Int_comparison_exp
    amount_left: Int_comparison_exp
    bigmap_key: bigint_comparison_exp
    currency: currency_bool_exp
    currency_id: bigint_comparison_exp
    end_price: bigint_comparison_exp
    expiry: timestamptz_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    id: bigint_comparison_exp
    level: Int_comparison_exp
    listing_sales: listing_sale_bool_exp
    marketplace: marketplace_contract_bool_exp
    marketplace_contract: String_comparison_exp
    ophash: String_comparison_exp
    price: bigint_comparison_exp
    price_xtz: bigint_comparison_exp
    seller: holder_bool_exp
    seller_address: String_comparison_exp
    shares: jsonb_comparison_exp
    start_price: bigint_comparison_exp
    status: auction_status_comparison_exp
    target: holder_bool_exp
    target_address: String_comparison_exp
    timestamp: timestamptz_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
    update_level: Int_comparison_exp
    update_ophash: String_comparison_exp
    update_timestamp: timestamptz_comparison_exp
}

"order by max() on columns of table \"listing\""
input listing_max_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    expiry: order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller_address: order_by
    start_price: order_by
    status: order_by
    target_address: order_by
    timestamp: order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"order by min() on columns of table \"listing\""
input listing_min_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    expiry: order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller_address: order_by
    start_price: order_by
    status: order_by
    target_address: order_by
    timestamp: order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"Ordering options when selecting data from \"listing\"."
input listing_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency: currency_order_by
    currency_id: order_by
    end_price: order_by
    expiry: order_by
    fa: fa_order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    listing_sales_aggregate: listing_sale_aggregate_order_by
    marketplace: marketplace_contract_order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller: holder_order_by
    seller_address: order_by
    shares: order_by
    start_price: order_by
    status: order_by
    target: holder_order_by
    target_address: order_by
    timestamp: order_by
    token: token_order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"order by aggregate values of table \"listing_sale\""
input listing_sale_aggregate_order_by {
    avg: listing_sale_avg_order_by
    count: order_by
    max: listing_sale_max_order_by
    min: listing_sale_min_order_by
    stddev: listing_sale_stddev_order_by
    stddev_pop: listing_sale_stddev_pop_order_by
    stddev_samp: listing_sale_stddev_samp_order_by
    sum: listing_sale_sum_order_by
    var_pop: listing_sale_var_pop_order_by
    var_samp: listing_sale_var_samp_order_by
    variance: listing_sale_variance_order_by
}

"order by avg() on columns of table \"listing_sale\""
input listing_sale_avg_order_by {
    amount: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"listing_sale\". All fields are combined with a logical 'AND'."
input listing_sale_bool_exp {
    _and: [listing_sale_bool_exp!]
    _not: listing_sale_bool_exp
    _or: [listing_sale_bool_exp!]
    amount: Int_comparison_exp
    buyer: holder_bool_exp
    buyer_address: String_comparison_exp
    id: bigint_comparison_exp
    level: Int_comparison_exp
    listing: listing_bool_exp
    listing_id: bigint_comparison_exp
    marketplace: marketplace_contract_bool_exp
    marketplace_contract: String_comparison_exp
    ophash: String_comparison_exp
    price: bigint_comparison_exp
    price_xtz: bigint_comparison_exp
    seller: holder_bool_exp
    seller_address: String_comparison_exp
    sender: holder_bool_exp
    sender_address: String_comparison_exp
    timestamp: timestamptz_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
}

"order by max() on columns of table \"listing_sale\""
input listing_sale_max_order_by {
    amount: order_by
    buyer_address: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller_address: order_by
    sender_address: order_by
    timestamp: order_by
    token_pk: order_by
}

"order by min() on columns of table \"listing_sale\""
input listing_sale_min_order_by {
    amount: order_by
    buyer_address: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller_address: order_by
    sender_address: order_by
    timestamp: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"listing_sale\"."
input listing_sale_order_by {
    amount: order_by
    buyer: holder_order_by
    buyer_address: order_by
    id: order_by
    level: order_by
    listing: listing_order_by
    listing_id: order_by
    marketplace: marketplace_contract_order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller: holder_order_by
    seller_address: order_by
    sender: holder_order_by
    sender_address: order_by
    timestamp: order_by
    token: token_order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"listing_sale\""
input listing_sale_stddev_order_by {
    amount: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"listing_sale\""
input listing_sale_stddev_pop_order_by {
    amount: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"listing_sale\""
input listing_sale_stddev_samp_order_by {
    amount: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"Streaming cursor of the table \"listing_sale\""
input listing_sale_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: listing_sale_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input listing_sale_stream_cursor_value_input {
    amount: Int
    buyer_address: String
    id: bigint
    level: Int
    listing_id: bigint
    marketplace_contract: String
    ophash: String
    price: bigint
    price_xtz: bigint
    seller_address: String
    sender_address: String
    timestamp: timestamptz
    token_pk: bigint
}

"order by sum() on columns of table \"listing_sale\""
input listing_sale_sum_order_by {
    amount: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by var_pop() on columns of table \"listing_sale\""
input listing_sale_var_pop_order_by {
    amount: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by var_samp() on columns of table \"listing_sale\""
input listing_sale_var_samp_order_by {
    amount: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by variance() on columns of table \"listing_sale\""
input listing_sale_variance_order_by {
    amount: order_by
    id: order_by
    level: order_by
    listing_id: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"listing\""
input listing_stddev_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    start_price: order_by
    token_pk: order_by
    update_level: order_by
}

"order by stddev_pop() on columns of table \"listing\""
input listing_stddev_pop_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    start_price: order_by
    token_pk: order_by
    update_level: order_by
}

"order by stddev_samp() on columns of table \"listing\""
input listing_stddev_samp_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    start_price: order_by
    token_pk: order_by
    update_level: order_by
}

"Streaming cursor of the table \"listing\""
input listing_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: listing_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input listing_stream_cursor_value_input {
    amount: Int
    amount_left: Int
    bigmap_key: bigint
    currency_id: bigint
    end_price: bigint
    expiry: timestamptz
    fa_contract: String
    id: bigint
    level: Int
    marketplace_contract: String
    ophash: String
    price: bigint
    price_xtz: bigint
    seller_address: String
    shares: jsonb
    start_price: bigint
    status: auction_status
    target_address: String
    timestamp: timestamptz
    token_pk: bigint
    update_level: Int
    update_ophash: String
    update_timestamp: timestamptz
}

"order by sum() on columns of table \"listing\""
input listing_sum_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    start_price: order_by
    token_pk: order_by
    update_level: order_by
}

"order by var_pop() on columns of table \"listing\""
input listing_var_pop_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    start_price: order_by
    token_pk: order_by
    update_level: order_by
}

"order by var_samp() on columns of table \"listing\""
input listing_var_samp_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    start_price: order_by
    token_pk: order_by
    update_level: order_by
}

"order by variance() on columns of table \"listing\""
input listing_variance_order_by {
    amount: order_by
    amount_left: order_by
    bigmap_key: order_by
    currency_id: order_by
    end_price: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    start_price: order_by
    token_pk: order_by
    update_level: order_by
}

"Boolean expression to filter rows from the table \"marketplace_contract\". All fields are combined with a logical 'AND'."
input marketplace_contract_bool_exp {
    _and: [marketplace_contract_bool_exp!]
    _not: marketplace_contract_bool_exp
    _or: [marketplace_contract_bool_exp!]
    contract: String_comparison_exp
    events: event_bool_exp
    group: String_comparison_exp
    name: String_comparison_exp
    subgroup: String_comparison_exp
}

"Ordering options when selecting data from \"marketplace_contract\"."
input marketplace_contract_order_by {
    contract: order_by
    events_aggregate: event_aggregate_order_by
    group: order_by
    name: order_by
    subgroup: order_by
}

"Streaming cursor of the table \"marketplace_contract\""
input marketplace_contract_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: marketplace_contract_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input marketplace_contract_stream_cursor_value_input {
    contract: String
    group: String
    name: String
    subgroup: String
}

"Boolean expression to compare columns of type \"marketplace_event_type\". All fields are combined with logical 'AND'."
input marketplace_event_type_comparison_exp {
    _eq: marketplace_event_type
    _gt: marketplace_event_type
    _gte: marketplace_event_type
    _in: [marketplace_event_type!]
    _is_null: Boolean
    _lt: marketplace_event_type
    _lte: marketplace_event_type
    _neq: marketplace_event_type
    _nin: [marketplace_event_type!]
}

"Boolean expression to compare columns of type \"metadata_status\". All fields are combined with logical 'AND'."
input metadata_status_comparison_exp {
    _eq: metadata_status
    _gt: metadata_status
    _gte: metadata_status
    _in: [metadata_status!]
    _is_null: Boolean
    _lt: metadata_status
    _lte: metadata_status
    _neq: metadata_status
    _nin: [metadata_status!]
}

"Boolean expression to compare columns of type \"numeric\". All fields are combined with logical 'AND'."
input numeric_comparison_exp {
    _eq: numeric
    _gt: numeric
    _gte: numeric
    _in: [numeric!]
    _is_null: Boolean
    _lt: numeric
    _lte: numeric
    _neq: numeric
    _nin: [numeric!]
}

"order by aggregate values of table \"offer\""
input offer_aggregate_order_by {
    avg: offer_avg_order_by
    count: order_by
    max: offer_max_order_by
    min: offer_min_order_by
    stddev: offer_stddev_order_by
    stddev_pop: offer_stddev_pop_order_by
    stddev_samp: offer_stddev_samp_order_by
    sum: offer_sum_order_by
    var_pop: offer_var_pop_order_by
    var_samp: offer_var_samp_order_by
    variance: offer_variance_order_by
}

"order by avg() on columns of table \"offer\""
input offer_avg_order_by {
    bigmap_key: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"Boolean expression to filter rows from the table \"offer\". All fields are combined with a logical 'AND'."
input offer_bool_exp {
    _and: [offer_bool_exp!]
    _not: offer_bool_exp
    _or: [offer_bool_exp!]
    bigmap_key: bigint_comparison_exp
    buyer: holder_bool_exp
    buyer_address: String_comparison_exp
    collection_offer: String_comparison_exp
    currency: currency_bool_exp
    currency_id: bigint_comparison_exp
    expiry: timestamptz_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    id: bigint_comparison_exp
    level: Int_comparison_exp
    marketplace: marketplace_contract_bool_exp
    marketplace_contract: String_comparison_exp
    ophash: String_comparison_exp
    price: bigint_comparison_exp
    price_xtz: bigint_comparison_exp
    seller: holder_bool_exp
    seller_address: String_comparison_exp
    shares: jsonb_comparison_exp
    status: auction_status_comparison_exp
    target: holder_bool_exp
    target_address: String_comparison_exp
    timestamp: timestamptz_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
    update_level: Int_comparison_exp
    update_ophash: String_comparison_exp
    update_timestamp: timestamptz_comparison_exp
}

"order by max() on columns of table \"offer\""
input offer_max_order_by {
    bigmap_key: order_by
    buyer_address: order_by
    collection_offer: order_by
    currency_id: order_by
    expiry: order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller_address: order_by
    status: order_by
    target_address: order_by
    timestamp: order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"order by min() on columns of table \"offer\""
input offer_min_order_by {
    bigmap_key: order_by
    buyer_address: order_by
    collection_offer: order_by
    currency_id: order_by
    expiry: order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller_address: order_by
    status: order_by
    target_address: order_by
    timestamp: order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"Ordering options when selecting data from \"offer\"."
input offer_order_by {
    bigmap_key: order_by
    buyer: holder_order_by
    buyer_address: order_by
    collection_offer: order_by
    currency: currency_order_by
    currency_id: order_by
    expiry: order_by
    fa: fa_order_by
    fa_contract: order_by
    id: order_by
    level: order_by
    marketplace: marketplace_contract_order_by
    marketplace_contract: order_by
    ophash: order_by
    price: order_by
    price_xtz: order_by
    seller: holder_order_by
    seller_address: order_by
    shares: order_by
    status: order_by
    target: holder_order_by
    target_address: order_by
    timestamp: order_by
    token: token_order_by
    token_pk: order_by
    update_level: order_by
    update_ophash: order_by
    update_timestamp: order_by
}

"order by stddev() on columns of table \"offer\""
input offer_stddev_order_by {
    bigmap_key: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by stddev_pop() on columns of table \"offer\""
input offer_stddev_pop_order_by {
    bigmap_key: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by stddev_samp() on columns of table \"offer\""
input offer_stddev_samp_order_by {
    bigmap_key: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"Streaming cursor of the table \"offer\""
input offer_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: offer_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input offer_stream_cursor_value_input {
    bigmap_key: bigint
    buyer_address: String
    collection_offer: String
    currency_id: bigint
    expiry: timestamptz
    fa_contract: String
    id: bigint
    level: Int
    marketplace_contract: String
    ophash: String
    price: bigint
    price_xtz: bigint
    seller_address: String
    shares: jsonb
    status: auction_status
    target_address: String
    timestamp: timestamptz
    token_pk: bigint
    update_level: Int
    update_ophash: String
    update_timestamp: timestamptz
}

"order by sum() on columns of table \"offer\""
input offer_sum_order_by {
    bigmap_key: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by var_pop() on columns of table \"offer\""
input offer_var_pop_order_by {
    bigmap_key: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by var_samp() on columns of table \"offer\""
input offer_var_samp_order_by {
    bigmap_key: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"order by variance() on columns of table \"offer\""
input offer_variance_order_by {
    bigmap_key: order_by
    currency_id: order_by
    id: order_by
    level: order_by
    price: order_by
    price_xtz: order_by
    token_pk: order_by
    update_level: order_by
}

"Boolean expression to filter rows from the table \"open_edition_active\". All fields are combined with a logical 'AND'."
input open_edition_active_bool_exp {
    _and: [open_edition_active_bool_exp!]
    _not: open_edition_active_bool_exp
    _or: [open_edition_active_bool_exp!]
    airdrop_capacity: Int_comparison_exp
    burn_recipe: jsonb_comparison_exp
    end_time: timestamptz_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    level: Int_comparison_exp
    max_per_wallet: Int_comparison_exp
    ophash: String_comparison_exp
    price: bigint_comparison_exp
    seller: holder_bool_exp
    seller_address: String_comparison_exp
    shares: jsonb_comparison_exp
    shares_total: Int_comparison_exp
    start_time: timestamptz_comparison_exp
    timestamp: timestamptz_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
}

"Ordering options when selecting data from \"open_edition_active\"."
input open_edition_active_order_by {
    airdrop_capacity: order_by
    burn_recipe: order_by
    end_time: order_by
    fa: fa_order_by
    fa_contract: order_by
    level: order_by
    max_per_wallet: order_by
    ophash: order_by
    price: order_by
    seller: holder_order_by
    seller_address: order_by
    shares: order_by
    shares_total: order_by
    start_time: order_by
    timestamp: order_by
    token: token_order_by
    token_pk: order_by
}

"Streaming cursor of the table \"open_edition_active\""
input open_edition_active_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: open_edition_active_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input open_edition_active_stream_cursor_value_input {
    airdrop_capacity: Int
    burn_recipe: jsonb
    end_time: timestamptz
    fa_contract: String
    level: Int
    max_per_wallet: Int
    ophash: String
    price: bigint
    seller_address: String
    shares: jsonb
    shares_total: Int
    start_time: timestamptz
    timestamp: timestamptz
    token_pk: bigint
}

"order by aggregate values of table \"open_edition\""
input open_edition_aggregate_order_by {
    avg: open_edition_avg_order_by
    count: order_by
    max: open_edition_max_order_by
    min: open_edition_min_order_by
    stddev: open_edition_stddev_order_by
    stddev_pop: open_edition_stddev_pop_order_by
    stddev_samp: open_edition_stddev_samp_order_by
    sum: open_edition_sum_order_by
    var_pop: open_edition_var_pop_order_by
    var_samp: open_edition_var_samp_order_by
    variance: open_edition_variance_order_by
}

"order by avg() on columns of table \"open_edition\""
input open_edition_avg_order_by {
    airdrop_capacity: order_by
    level: order_by
    max_per_wallet: order_by
    price: order_by
    shares_total: order_by
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"open_edition\". All fields are combined with a logical 'AND'."
input open_edition_bool_exp {
    _and: [open_edition_bool_exp!]
    _not: open_edition_bool_exp
    _or: [open_edition_bool_exp!]
    airdrop_capacity: Int_comparison_exp
    burn_recipe: jsonb_comparison_exp
    end_time: timestamptz_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    level: Int_comparison_exp
    max_per_wallet: Int_comparison_exp
    ophash: String_comparison_exp
    price: bigint_comparison_exp
    seller: holder_bool_exp
    seller_address: String_comparison_exp
    shares: jsonb_comparison_exp
    shares_total: Int_comparison_exp
    start_time: timestamptz_comparison_exp
    timestamp: timestamptz_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
    valid_royalties: Boolean_comparison_exp
}

"order by max() on columns of table \"open_edition\""
input open_edition_max_order_by {
    airdrop_capacity: order_by
    end_time: order_by
    fa_contract: order_by
    level: order_by
    max_per_wallet: order_by
    ophash: order_by
    price: order_by
    seller_address: order_by
    shares_total: order_by
    start_time: order_by
    timestamp: order_by
    token_pk: order_by
}

"order by min() on columns of table \"open_edition\""
input open_edition_min_order_by {
    airdrop_capacity: order_by
    end_time: order_by
    fa_contract: order_by
    level: order_by
    max_per_wallet: order_by
    ophash: order_by
    price: order_by
    seller_address: order_by
    shares_total: order_by
    start_time: order_by
    timestamp: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"open_edition\"."
input open_edition_order_by {
    airdrop_capacity: order_by
    burn_recipe: order_by
    end_time: order_by
    fa: fa_order_by
    fa_contract: order_by
    level: order_by
    max_per_wallet: order_by
    ophash: order_by
    price: order_by
    seller: holder_order_by
    seller_address: order_by
    shares: order_by
    shares_total: order_by
    start_time: order_by
    timestamp: order_by
    token: token_order_by
    token_pk: order_by
    valid_royalties: order_by
}

"order by stddev() on columns of table \"open_edition\""
input open_edition_stddev_order_by {
    airdrop_capacity: order_by
    level: order_by
    max_per_wallet: order_by
    price: order_by
    shares_total: order_by
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"open_edition\""
input open_edition_stddev_pop_order_by {
    airdrop_capacity: order_by
    level: order_by
    max_per_wallet: order_by
    price: order_by
    shares_total: order_by
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"open_edition\""
input open_edition_stddev_samp_order_by {
    airdrop_capacity: order_by
    level: order_by
    max_per_wallet: order_by
    price: order_by
    shares_total: order_by
    token_pk: order_by
}

"Streaming cursor of the table \"open_edition\""
input open_edition_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: open_edition_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input open_edition_stream_cursor_value_input {
    airdrop_capacity: Int
    burn_recipe: jsonb
    end_time: timestamptz
    fa_contract: String
    level: Int
    max_per_wallet: Int
    ophash: String
    price: bigint
    seller_address: String
    shares: jsonb
    shares_total: Int
    start_time: timestamptz
    timestamp: timestamptz
    token_pk: bigint
    valid_royalties: Boolean
}

"order by sum() on columns of table \"open_edition\""
input open_edition_sum_order_by {
    airdrop_capacity: order_by
    level: order_by
    max_per_wallet: order_by
    price: order_by
    shares_total: order_by
    token_pk: order_by
}

"order by var_pop() on columns of table \"open_edition\""
input open_edition_var_pop_order_by {
    airdrop_capacity: order_by
    level: order_by
    max_per_wallet: order_by
    price: order_by
    shares_total: order_by
    token_pk: order_by
}

"order by var_samp() on columns of table \"open_edition\""
input open_edition_var_samp_order_by {
    airdrop_capacity: order_by
    level: order_by
    max_per_wallet: order_by
    price: order_by
    shares_total: order_by
    token_pk: order_by
}

"order by variance() on columns of table \"open_edition\""
input open_edition_variance_order_by {
    airdrop_capacity: order_by
    level: order_by
    max_per_wallet: order_by
    price: order_by
    shares_total: order_by
    token_pk: order_by
}

"order by aggregate values of table \"royalties\""
input royalties_aggregate_order_by {
    avg: royalties_avg_order_by
    count: order_by
    max: royalties_max_order_by
    min: royalties_min_order_by
    stddev: royalties_stddev_order_by
    stddev_pop: royalties_stddev_pop_order_by
    stddev_samp: royalties_stddev_samp_order_by
    sum: royalties_sum_order_by
    var_pop: royalties_var_pop_order_by
    var_samp: royalties_var_samp_order_by
    variance: royalties_variance_order_by
}

"order by avg() on columns of table \"royalties\""
input royalties_avg_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"royalties\". All fields are combined with a logical 'AND'."
input royalties_bool_exp {
    _and: [royalties_bool_exp!]
    _not: royalties_bool_exp
    _or: [royalties_bool_exp!]
    amount: Int_comparison_exp
    decimals: Int_comparison_exp
    holder: holder_bool_exp
    id: bigint_comparison_exp
    receiver_address: String_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
}

"order by max() on columns of table \"royalties\""
input royalties_max_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    receiver_address: order_by
    token_pk: order_by
}

"order by min() on columns of table \"royalties\""
input royalties_min_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    receiver_address: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"royalties\"."
input royalties_order_by {
    amount: order_by
    decimals: order_by
    holder: holder_order_by
    id: order_by
    receiver_address: order_by
    token: token_order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"royalties\""
input royalties_stddev_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"royalties\""
input royalties_stddev_pop_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"royalties\""
input royalties_stddev_samp_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    token_pk: order_by
}

"Streaming cursor of the table \"royalties\""
input royalties_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: royalties_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input royalties_stream_cursor_value_input {
    amount: Int
    decimals: Int
    id: bigint
    receiver_address: String
    token_pk: bigint
}

"order by sum() on columns of table \"royalties\""
input royalties_sum_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    token_pk: order_by
}

"order by var_pop() on columns of table \"royalties\""
input royalties_var_pop_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    token_pk: order_by
}

"order by var_samp() on columns of table \"royalties\""
input royalties_var_samp_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    token_pk: order_by
}

"order by variance() on columns of table \"royalties\""
input royalties_variance_order_by {
    amount: order_by
    decimals: order_by
    id: order_by
    token_pk: order_by
}

"order by aggregate values of table \"sales_stat\""
input sales_stat_aggregate_order_by {
    avg: sales_stat_avg_order_by
    count: order_by
    max: sales_stat_max_order_by
    min: sales_stat_min_order_by
    stddev: sales_stat_stddev_order_by
    stddev_pop: sales_stat_stddev_pop_order_by
    stddev_samp: sales_stat_stddev_samp_order_by
    sum: sales_stat_sum_order_by
    var_pop: sales_stat_var_pop_order_by
    var_samp: sales_stat_var_samp_order_by
    variance: sales_stat_variance_order_by
}

"order by avg() on columns of table \"sales_stat\""
input sales_stat_avg_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    volume: order_by
}

"Boolean expression to filter rows from the table \"sales_stat\". All fields are combined with a logical 'AND'."
input sales_stat_bool_exp {
    _and: [sales_stat_bool_exp!]
    _not: sales_stat_bool_exp
    _or: [sales_stat_bool_exp!]
    id: bigint_comparison_exp
    interval_days: Int_comparison_exp
    rank: Int_comparison_exp
    subject: holder_bool_exp
    subject_address: String_comparison_exp
    type: sales_stat_type_comparison_exp
    volume: bigint_comparison_exp
}

"order by max() on columns of table \"sales_stat\""
input sales_stat_max_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    subject_address: order_by
    type: order_by
    volume: order_by
}

"order by min() on columns of table \"sales_stat\""
input sales_stat_min_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    subject_address: order_by
    type: order_by
    volume: order_by
}

"Ordering options when selecting data from \"sales_stat\"."
input sales_stat_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    subject: holder_order_by
    subject_address: order_by
    type: order_by
    volume: order_by
}

"order by stddev() on columns of table \"sales_stat\""
input sales_stat_stddev_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    volume: order_by
}

"order by stddev_pop() on columns of table \"sales_stat\""
input sales_stat_stddev_pop_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    volume: order_by
}

"order by stddev_samp() on columns of table \"sales_stat\""
input sales_stat_stddev_samp_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    volume: order_by
}

"Streaming cursor of the table \"sales_stat\""
input sales_stat_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: sales_stat_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input sales_stat_stream_cursor_value_input {
    id: bigint
    interval_days: Int
    rank: Int
    subject_address: String
    type: sales_stat_type
    volume: bigint
}

"order by sum() on columns of table \"sales_stat\""
input sales_stat_sum_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    volume: order_by
}

"Boolean expression to compare columns of type \"sales_stat_type\". All fields are combined with logical 'AND'."
input sales_stat_type_comparison_exp {
    _eq: sales_stat_type
    _gt: sales_stat_type
    _gte: sales_stat_type
    _in: [sales_stat_type!]
    _is_null: Boolean
    _lt: sales_stat_type
    _lte: sales_stat_type
    _neq: sales_stat_type
    _nin: [sales_stat_type!]
}

"order by var_pop() on columns of table \"sales_stat\""
input sales_stat_var_pop_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    volume: order_by
}

"order by var_samp() on columns of table \"sales_stat\""
input sales_stat_var_samp_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    volume: order_by
}

"order by variance() on columns of table \"sales_stat\""
input sales_stat_variance_order_by {
    id: order_by
    interval_days: order_by
    rank: order_by
    volume: order_by
}

"Boolean expression to filter rows from the table \"tag\". All fields are combined with a logical 'AND'."
input tag_bool_exp {
    _and: [tag_bool_exp!]
    _not: tag_bool_exp
    _or: [tag_bool_exp!]
    id: bigint_comparison_exp
    name: String_comparison_exp
    token_count: bigint_comparison_exp
    tokens: token_tag_bool_exp
}

"Ordering options when selecting data from \"tag\"."
input tag_order_by {
    id: order_by
    name: order_by
    token_count: order_by
    tokens_aggregate: token_tag_aggregate_order_by
}

"Streaming cursor of the table \"tag\""
input tag_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: tag_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input tag_stream_cursor_value_input {
    id: bigint
    name: String
    token_count: bigint
}

"Boolean expression to filter rows from the table \"tezos_storage\". All fields are combined with a logical 'AND'."
input tezos_storage_bool_exp {
    _and: [tezos_storage_bool_exp!]
    _not: tezos_storage_bool_exp
    _or: [tezos_storage_bool_exp!]
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    id: bigint_comparison_exp
    tzip16_key: String_comparison_exp
    tzip16_value: String_comparison_exp
}

"Ordering options when selecting data from \"tezos_storage\"."
input tezos_storage_order_by {
    fa: fa_order_by
    fa_contract: order_by
    id: order_by
    tzip16_key: order_by
    tzip16_value: order_by
}

"Streaming cursor of the table \"tezos_storage\""
input tezos_storage_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: tezos_storage_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input tezos_storage_stream_cursor_value_input {
    fa_contract: String
    id: bigint
    tzip16_key: String
    tzip16_value: String
}

"Boolean expression to compare columns of type \"timestamptz\". All fields are combined with logical 'AND'."
input timestamptz_comparison_exp {
    _eq: timestamptz
    _gt: timestamptz
    _gte: timestamptz
    _in: [timestamptz!]
    _is_null: Boolean
    _lt: timestamptz
    _lte: timestamptz
    _neq: timestamptz
    _nin: [timestamptz!]
}

"order by aggregate values of table \"token\""
input token_aggregate_order_by {
    avg: token_avg_order_by
    count: order_by
    max: token_max_order_by
    min: token_min_order_by
    stddev: token_stddev_order_by
    stddev_pop: token_stddev_pop_order_by
    stddev_samp: token_stddev_samp_order_by
    sum: token_sum_order_by
    var_pop: token_var_pop_order_by
    var_samp: token_var_samp_order_by
    variance: token_variance_order_by
}

"order by aggregate values of table \"token_attribute\""
input token_attribute_aggregate_order_by {
    avg: token_attribute_avg_order_by
    count: order_by
    max: token_attribute_max_order_by
    min: token_attribute_min_order_by
    stddev: token_attribute_stddev_order_by
    stddev_pop: token_attribute_stddev_pop_order_by
    stddev_samp: token_attribute_stddev_samp_order_by
    sum: token_attribute_sum_order_by
    var_pop: token_attribute_var_pop_order_by
    var_samp: token_attribute_var_samp_order_by
    variance: token_attribute_variance_order_by
}

"order by avg() on columns of table \"token_attribute\""
input token_attribute_avg_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"token_attribute\". All fields are combined with a logical 'AND'."
input token_attribute_bool_exp {
    _and: [token_attribute_bool_exp!]
    _not: token_attribute_bool_exp
    _or: [token_attribute_bool_exp!]
    attribute: attribute_bool_exp
    attribute_id: bigint_comparison_exp
    id: bigint_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
}

"order by max() on columns of table \"token_attribute\""
input token_attribute_max_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"order by min() on columns of table \"token_attribute\""
input token_attribute_min_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"token_attribute\"."
input token_attribute_order_by {
    attribute: attribute_order_by
    attribute_id: order_by
    id: order_by
    token: token_order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"token_attribute\""
input token_attribute_stddev_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"token_attribute\""
input token_attribute_stddev_pop_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"token_attribute\""
input token_attribute_stddev_samp_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"Streaming cursor of the table \"token_attribute\""
input token_attribute_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: token_attribute_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input token_attribute_stream_cursor_value_input {
    attribute_id: bigint
    id: bigint
    token_pk: bigint
}

"order by sum() on columns of table \"token_attribute\""
input token_attribute_sum_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"order by var_pop() on columns of table \"token_attribute\""
input token_attribute_var_pop_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"order by var_samp() on columns of table \"token_attribute\""
input token_attribute_var_samp_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"order by variance() on columns of table \"token_attribute\""
input token_attribute_variance_order_by {
    attribute_id: order_by
    id: order_by
    token_pk: order_by
}

"order by avg() on columns of table \"token\""
input token_avg_order_by {
    average: order_by
    decimals: order_by
    highest_offer: order_by
    level: order_by
    lowest_ask: order_by
    pk: order_by
    supply: order_by
}

"Boolean expression to filter rows from the table \"token\". All fields are combined with a logical 'AND'."
input token_bool_exp {
    _and: [token_bool_exp!]
    _not: token_bool_exp
    _or: [token_bool_exp!]
    artifact_uri: String_comparison_exp
    attributes: token_attribute_bool_exp
    average: bigint_comparison_exp
    creators: token_creator_bool_exp
    decimals: Int_comparison_exp
    description: String_comparison_exp
    display_uri: String_comparison_exp
    dutch_auctions: dutch_auction_bool_exp
    english_auctions: english_auction_bool_exp
    events: event_bool_exp
    extra: jsonb_comparison_exp
    fa: fa_bool_exp
    fa_contract: String_comparison_exp
    flag: flag_type_comparison_exp
    highest_offer: bigint_comparison_exp
    holders: token_holder_bool_exp
    is_boolean_amount: Boolean_comparison_exp
    last_listed: timestamptz_comparison_exp
    last_metadata_update: timestamptz_comparison_exp
    level: Int_comparison_exp
    listing_sales: listing_sale_bool_exp
    listings: listing_bool_exp
    lowest_ask: bigint_comparison_exp
    metadata: String_comparison_exp
    metadata_status: metadata_status_comparison_exp
    mime: String_comparison_exp
    name: String_comparison_exp
    offers: offer_bool_exp
    open_edition: open_edition_bool_exp
    operators: token_operator_bool_exp
    ophash: String_comparison_exp
    pk: bigint_comparison_exp
    rights: String_comparison_exp
    royalties: royalties_bool_exp
    supply: bigint_comparison_exp
    symbol: String_comparison_exp
    tags: token_tag_bool_exp
    thumbnail_uri: String_comparison_exp
    timestamp: timestamptz_comparison_exp
    token_id: String_comparison_exp
    tzip16_key: String_comparison_exp
}

"order by aggregate values of table \"token_creator\""
input token_creator_aggregate_order_by {
    avg: token_creator_avg_order_by
    count: order_by
    max: token_creator_max_order_by
    min: token_creator_min_order_by
    stddev: token_creator_stddev_order_by
    stddev_pop: token_creator_stddev_pop_order_by
    stddev_samp: token_creator_stddev_samp_order_by
    sum: token_creator_sum_order_by
    var_pop: token_creator_var_pop_order_by
    var_samp: token_creator_var_samp_order_by
    variance: token_creator_variance_order_by
}

"order by avg() on columns of table \"token_creator\""
input token_creator_avg_order_by {
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"token_creator\". All fields are combined with a logical 'AND'."
input token_creator_bool_exp {
    _and: [token_creator_bool_exp!]
    _not: token_creator_bool_exp
    _or: [token_creator_bool_exp!]
    creator_address: String_comparison_exp
    holder: holder_bool_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
    verified: Boolean_comparison_exp
}

"order by max() on columns of table \"token_creator\""
input token_creator_max_order_by {
    creator_address: order_by
    token_pk: order_by
}

"order by min() on columns of table \"token_creator\""
input token_creator_min_order_by {
    creator_address: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"token_creator\"."
input token_creator_order_by {
    creator_address: order_by
    holder: holder_order_by
    token: token_order_by
    token_pk: order_by
    verified: order_by
}

"order by stddev() on columns of table \"token_creator\""
input token_creator_stddev_order_by {
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"token_creator\""
input token_creator_stddev_pop_order_by {
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"token_creator\""
input token_creator_stddev_samp_order_by {
    token_pk: order_by
}

"Streaming cursor of the table \"token_creator\""
input token_creator_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: token_creator_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input token_creator_stream_cursor_value_input {
    creator_address: String
    token_pk: bigint
    verified: Boolean
}

"order by sum() on columns of table \"token_creator\""
input token_creator_sum_order_by {
    token_pk: order_by
}

"order by var_pop() on columns of table \"token_creator\""
input token_creator_var_pop_order_by {
    token_pk: order_by
}

"order by var_samp() on columns of table \"token_creator\""
input token_creator_var_samp_order_by {
    token_pk: order_by
}

"order by variance() on columns of table \"token_creator\""
input token_creator_variance_order_by {
    token_pk: order_by
}

"order by aggregate values of table \"token_holder\""
input token_holder_aggregate_order_by {
    avg: token_holder_avg_order_by
    count: order_by
    max: token_holder_max_order_by
    min: token_holder_min_order_by
    stddev: token_holder_stddev_order_by
    stddev_pop: token_holder_stddev_pop_order_by
    stddev_samp: token_holder_stddev_samp_order_by
    sum: token_holder_sum_order_by
    var_pop: token_holder_var_pop_order_by
    var_samp: token_holder_var_samp_order_by
    variance: token_holder_variance_order_by
}

"order by avg() on columns of table \"token_holder\""
input token_holder_avg_order_by {
    quantity: order_by
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"token_holder\". All fields are combined with a logical 'AND'."
input token_holder_bool_exp {
    _and: [token_holder_bool_exp!]
    _not: token_holder_bool_exp
    _or: [token_holder_bool_exp!]
    holder: holder_bool_exp
    holder_address: String_comparison_exp
    last_incremented_at: timestamptz_comparison_exp
    quantity: numeric_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
}

"order by max() on columns of table \"token_holder\""
input token_holder_max_order_by {
    holder_address: order_by
    last_incremented_at: order_by
    quantity: order_by
    token_pk: order_by
}

"order by min() on columns of table \"token_holder\""
input token_holder_min_order_by {
    holder_address: order_by
    last_incremented_at: order_by
    quantity: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"token_holder\"."
input token_holder_order_by {
    holder: holder_order_by
    holder_address: order_by
    last_incremented_at: order_by
    quantity: order_by
    token: token_order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"token_holder\""
input token_holder_stddev_order_by {
    quantity: order_by
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"token_holder\""
input token_holder_stddev_pop_order_by {
    quantity: order_by
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"token_holder\""
input token_holder_stddev_samp_order_by {
    quantity: order_by
    token_pk: order_by
}

"Streaming cursor of the table \"token_holder\""
input token_holder_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: token_holder_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input token_holder_stream_cursor_value_input {
    holder_address: String
    last_incremented_at: timestamptz
    quantity: numeric
    token_pk: bigint
}

"order by sum() on columns of table \"token_holder\""
input token_holder_sum_order_by {
    quantity: order_by
    token_pk: order_by
}

"order by var_pop() on columns of table \"token_holder\""
input token_holder_var_pop_order_by {
    quantity: order_by
    token_pk: order_by
}

"order by var_samp() on columns of table \"token_holder\""
input token_holder_var_samp_order_by {
    quantity: order_by
    token_pk: order_by
}

"order by variance() on columns of table \"token_holder\""
input token_holder_variance_order_by {
    quantity: order_by
    token_pk: order_by
}

"order by max() on columns of table \"token\""
input token_max_order_by {
    artifact_uri: order_by
    average: order_by
    decimals: order_by
    description: order_by
    display_uri: order_by
    fa_contract: order_by
    flag: order_by
    highest_offer: order_by
    last_listed: order_by
    last_metadata_update: order_by
    level: order_by
    lowest_ask: order_by
    metadata: order_by
    metadata_status: order_by
    mime: order_by
    name: order_by
    ophash: order_by
    pk: order_by
    rights: order_by
    supply: order_by
    symbol: order_by
    thumbnail_uri: order_by
    timestamp: order_by
    token_id: order_by
    tzip16_key: order_by
}

"order by min() on columns of table \"token\""
input token_min_order_by {
    artifact_uri: order_by
    average: order_by
    decimals: order_by
    description: order_by
    display_uri: order_by
    fa_contract: order_by
    flag: order_by
    highest_offer: order_by
    last_listed: order_by
    last_metadata_update: order_by
    level: order_by
    lowest_ask: order_by
    metadata: order_by
    metadata_status: order_by
    mime: order_by
    name: order_by
    ophash: order_by
    pk: order_by
    rights: order_by
    supply: order_by
    symbol: order_by
    thumbnail_uri: order_by
    timestamp: order_by
    token_id: order_by
    tzip16_key: order_by
}

"order by aggregate values of table \"token_operator\""
input token_operator_aggregate_order_by {
    avg: token_operator_avg_order_by
    count: order_by
    max: token_operator_max_order_by
    min: token_operator_min_order_by
    stddev: token_operator_stddev_order_by
    stddev_pop: token_operator_stddev_pop_order_by
    stddev_samp: token_operator_stddev_samp_order_by
    sum: token_operator_sum_order_by
    var_pop: token_operator_var_pop_order_by
    var_samp: token_operator_var_samp_order_by
    variance: token_operator_variance_order_by
}

"order by avg() on columns of table \"token_operator\""
input token_operator_avg_order_by {
    amount: order_by
    id: order_by
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"token_operator\". All fields are combined with a logical 'AND'."
input token_operator_bool_exp {
    _and: [token_operator_bool_exp!]
    _not: token_operator_bool_exp
    _or: [token_operator_bool_exp!]
    allowed: Boolean_comparison_exp
    amount: numeric_comparison_exp
    id: bigint_comparison_exp
    operator: holder_bool_exp
    operator_address: String_comparison_exp
    owner: holder_bool_exp
    owner_address: String_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
}

"order by max() on columns of table \"token_operator\""
input token_operator_max_order_by {
    amount: order_by
    id: order_by
    operator_address: order_by
    owner_address: order_by
    token_pk: order_by
}

"order by min() on columns of table \"token_operator\""
input token_operator_min_order_by {
    amount: order_by
    id: order_by
    operator_address: order_by
    owner_address: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"token_operator\"."
input token_operator_order_by {
    allowed: order_by
    amount: order_by
    id: order_by
    operator: holder_order_by
    operator_address: order_by
    owner: holder_order_by
    owner_address: order_by
    token: token_order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"token_operator\""
input token_operator_stddev_order_by {
    amount: order_by
    id: order_by
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"token_operator\""
input token_operator_stddev_pop_order_by {
    amount: order_by
    id: order_by
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"token_operator\""
input token_operator_stddev_samp_order_by {
    amount: order_by
    id: order_by
    token_pk: order_by
}

"Streaming cursor of the table \"token_operator\""
input token_operator_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: token_operator_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input token_operator_stream_cursor_value_input {
    allowed: Boolean
    amount: numeric
    id: bigint
    operator_address: String
    owner_address: String
    token_pk: bigint
}

"order by sum() on columns of table \"token_operator\""
input token_operator_sum_order_by {
    amount: order_by
    id: order_by
    token_pk: order_by
}

"order by var_pop() on columns of table \"token_operator\""
input token_operator_var_pop_order_by {
    amount: order_by
    id: order_by
    token_pk: order_by
}

"order by var_samp() on columns of table \"token_operator\""
input token_operator_var_samp_order_by {
    amount: order_by
    id: order_by
    token_pk: order_by
}

"order by variance() on columns of table \"token_operator\""
input token_operator_variance_order_by {
    amount: order_by
    id: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"token\"."
input token_order_by {
    artifact_uri: order_by
    attributes_aggregate: token_attribute_aggregate_order_by
    average: order_by
    creators_aggregate: token_creator_aggregate_order_by
    decimals: order_by
    description: order_by
    display_uri: order_by
    dutch_auctions_aggregate: dutch_auction_aggregate_order_by
    english_auctions_aggregate: english_auction_aggregate_order_by
    events_aggregate: event_aggregate_order_by
    extra: order_by
    fa: fa_order_by
    fa_contract: order_by
    flag: order_by
    highest_offer: order_by
    holders_aggregate: token_holder_aggregate_order_by
    is_boolean_amount: order_by
    last_listed: order_by
    last_metadata_update: order_by
    level: order_by
    listing_sales_aggregate: listing_sale_aggregate_order_by
    listings_aggregate: listing_aggregate_order_by
    lowest_ask: order_by
    metadata: order_by
    metadata_status: order_by
    mime: order_by
    name: order_by
    offers_aggregate: offer_aggregate_order_by
    open_edition: open_edition_order_by
    operators_aggregate: token_operator_aggregate_order_by
    ophash: order_by
    pk: order_by
    rights: order_by
    royalties_aggregate: royalties_aggregate_order_by
    supply: order_by
    symbol: order_by
    tags_aggregate: token_tag_aggregate_order_by
    thumbnail_uri: order_by
    timestamp: order_by
    token_id: order_by
    tzip16_key: order_by
}

"Boolean expression to filter rows from the table \"token_registry\". All fields are combined with a logical 'AND'."
input token_registry_bool_exp {
    _and: [token_registry_bool_exp!]
    _not: token_registry_bool_exp
    _or: [token_registry_bool_exp!]
    active: Boolean_comparison_exp
    address: String_comparison_exp
    beneficiary: String_comparison_exp
    fee: Int_comparison_exp
    type: token_type_comparison_exp
}

"Ordering options when selecting data from \"token_registry\"."
input token_registry_order_by {
    active: order_by
    address: order_by
    beneficiary: order_by
    fee: order_by
    type: order_by
}

"Streaming cursor of the table \"token_registry\""
input token_registry_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: token_registry_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input token_registry_stream_cursor_value_input {
    active: Boolean
    address: String
    beneficiary: String
    fee: Int
    type: token_type
}

"order by stddev() on columns of table \"token\""
input token_stddev_order_by {
    average: order_by
    decimals: order_by
    highest_offer: order_by
    level: order_by
    lowest_ask: order_by
    pk: order_by
    supply: order_by
}

"order by stddev_pop() on columns of table \"token\""
input token_stddev_pop_order_by {
    average: order_by
    decimals: order_by
    highest_offer: order_by
    level: order_by
    lowest_ask: order_by
    pk: order_by
    supply: order_by
}

"order by stddev_samp() on columns of table \"token\""
input token_stddev_samp_order_by {
    average: order_by
    decimals: order_by
    highest_offer: order_by
    level: order_by
    lowest_ask: order_by
    pk: order_by
    supply: order_by
}

"Streaming cursor of the table \"token\""
input token_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: token_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input token_stream_cursor_value_input {
    artifact_uri: String
    average: bigint
    decimals: Int
    description: String
    display_uri: String
    extra: jsonb
    fa_contract: String
    flag: flag_type
    highest_offer: bigint
    is_boolean_amount: Boolean
    last_listed: timestamptz
    last_metadata_update: timestamptz
    level: Int
    lowest_ask: bigint
    metadata: String
    metadata_status: metadata_status
    mime: String
    name: String
    ophash: String
    pk: bigint
    rights: String
    supply: bigint
    symbol: String
    thumbnail_uri: String
    timestamp: timestamptz
    token_id: String
    tzip16_key: String
}

"order by sum() on columns of table \"token\""
input token_sum_order_by {
    average: order_by
    decimals: order_by
    highest_offer: order_by
    level: order_by
    lowest_ask: order_by
    pk: order_by
    supply: order_by
}

"order by aggregate values of table \"token_tag\""
input token_tag_aggregate_order_by {
    avg: token_tag_avg_order_by
    count: order_by
    max: token_tag_max_order_by
    min: token_tag_min_order_by
    stddev: token_tag_stddev_order_by
    stddev_pop: token_tag_stddev_pop_order_by
    stddev_samp: token_tag_stddev_samp_order_by
    sum: token_tag_sum_order_by
    var_pop: token_tag_var_pop_order_by
    var_samp: token_tag_var_samp_order_by
    variance: token_tag_variance_order_by
}

"order by avg() on columns of table \"token_tag\""
input token_tag_avg_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"token_tag\". All fields are combined with a logical 'AND'."
input token_tag_bool_exp {
    _and: [token_tag_bool_exp!]
    _not: token_tag_bool_exp
    _or: [token_tag_bool_exp!]
    id: bigint_comparison_exp
    tag: tag_bool_exp
    tag_id: bigint_comparison_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
}

"order by max() on columns of table \"token_tag\""
input token_tag_max_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"order by min() on columns of table \"token_tag\""
input token_tag_min_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"Ordering options when selecting data from \"token_tag\"."
input token_tag_order_by {
    id: order_by
    tag: tag_order_by
    tag_id: order_by
    token: token_order_by
    token_pk: order_by
}

"order by stddev() on columns of table \"token_tag\""
input token_tag_stddev_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"token_tag\""
input token_tag_stddev_pop_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"token_tag\""
input token_tag_stddev_samp_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"Streaming cursor of the table \"token_tag\""
input token_tag_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: token_tag_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input token_tag_stream_cursor_value_input {
    id: bigint
    tag_id: bigint
    token_pk: bigint
}

"order by sum() on columns of table \"token_tag\""
input token_tag_sum_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"order by var_pop() on columns of table \"token_tag\""
input token_tag_var_pop_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"order by var_samp() on columns of table \"token_tag\""
input token_tag_var_samp_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"order by variance() on columns of table \"token_tag\""
input token_tag_variance_order_by {
    id: order_by
    tag_id: order_by
    token_pk: order_by
}

"Boolean expression to compare columns of type \"token_type\". All fields are combined with logical 'AND'."
input token_type_comparison_exp {
    _eq: token_type
    _gt: token_type
    _gte: token_type
    _in: [token_type!]
    _is_null: Boolean
    _lt: token_type
    _lte: token_type
    _neq: token_type
    _nin: [token_type!]
}

"order by var_pop() on columns of table \"token\""
input token_var_pop_order_by {
    average: order_by
    decimals: order_by
    highest_offer: order_by
    level: order_by
    lowest_ask: order_by
    pk: order_by
    supply: order_by
}

"order by var_samp() on columns of table \"token\""
input token_var_samp_order_by {
    average: order_by
    decimals: order_by
    highest_offer: order_by
    level: order_by
    lowest_ask: order_by
    pk: order_by
    supply: order_by
}

"order by variance() on columns of table \"token\""
input token_variance_order_by {
    average: order_by
    decimals: order_by
    highest_offer: order_by
    level: order_by
    lowest_ask: order_by
    pk: order_by
    supply: order_by
}

"order by aggregate values of table \"tzd_domain\""
input tzd_domain_aggregate_order_by {
    avg: tzd_domain_avg_order_by
    count: order_by
    max: tzd_domain_max_order_by
    min: tzd_domain_min_order_by
    stddev: tzd_domain_stddev_order_by
    stddev_pop: tzd_domain_stddev_pop_order_by
    stddev_samp: tzd_domain_stddev_samp_order_by
    sum: tzd_domain_sum_order_by
    var_pop: tzd_domain_var_pop_order_by
    var_samp: tzd_domain_var_samp_order_by
    variance: tzd_domain_variance_order_by
}

"order by avg() on columns of table \"tzd_domain\""
input tzd_domain_avg_order_by {
    token_pk: order_by
}

"Boolean expression to filter rows from the table \"tzd_domain\". All fields are combined with a logical 'AND'."
input tzd_domain_bool_exp {
    _and: [tzd_domain_bool_exp!]
    _not: tzd_domain_bool_exp
    _or: [tzd_domain_bool_exp!]
    expiry: timestamptz_comparison_exp
    id: String_comparison_exp
    owner: String_comparison_exp
    records: tzd_record_bool_exp
    token: token_bool_exp
    token_pk: bigint_comparison_exp
    tzd_tld: tzd_tld_bool_exp
    tzd_tld_id: String_comparison_exp
}

"order by max() on columns of table \"tzd_domain\""
input tzd_domain_max_order_by {
    expiry: order_by
    id: order_by
    owner: order_by
    token_pk: order_by
    tzd_tld_id: order_by
}

"order by min() on columns of table \"tzd_domain\""
input tzd_domain_min_order_by {
    expiry: order_by
    id: order_by
    owner: order_by
    token_pk: order_by
    tzd_tld_id: order_by
}

"Ordering options when selecting data from \"tzd_domain\"."
input tzd_domain_order_by {
    expiry: order_by
    id: order_by
    owner: order_by
    records_aggregate: tzd_record_aggregate_order_by
    token: token_order_by
    token_pk: order_by
    tzd_tld: tzd_tld_order_by
    tzd_tld_id: order_by
}

"order by stddev() on columns of table \"tzd_domain\""
input tzd_domain_stddev_order_by {
    token_pk: order_by
}

"order by stddev_pop() on columns of table \"tzd_domain\""
input tzd_domain_stddev_pop_order_by {
    token_pk: order_by
}

"order by stddev_samp() on columns of table \"tzd_domain\""
input tzd_domain_stddev_samp_order_by {
    token_pk: order_by
}

"Streaming cursor of the table \"tzd_domain\""
input tzd_domain_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: tzd_domain_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input tzd_domain_stream_cursor_value_input {
    expiry: timestamptz
    id: String
    owner: String
    token_pk: bigint
    tzd_tld_id: String
}

"order by sum() on columns of table \"tzd_domain\""
input tzd_domain_sum_order_by {
    token_pk: order_by
}

"order by var_pop() on columns of table \"tzd_domain\""
input tzd_domain_var_pop_order_by {
    token_pk: order_by
}

"order by var_samp() on columns of table \"tzd_domain\""
input tzd_domain_var_samp_order_by {
    token_pk: order_by
}

"order by variance() on columns of table \"tzd_domain\""
input tzd_domain_variance_order_by {
    token_pk: order_by
}

"order by aggregate values of table \"tzd_record\""
input tzd_record_aggregate_order_by {
    count: order_by
    max: tzd_record_max_order_by
    min: tzd_record_min_order_by
}

"Boolean expression to filter rows from the table \"tzd_record\". All fields are combined with a logical 'AND'."
input tzd_record_bool_exp {
    _and: [tzd_record_bool_exp!]
    _not: tzd_record_bool_exp
    _or: [tzd_record_bool_exp!]
    domain: tzd_domain_bool_exp
    domain_id: String_comparison_exp
    id: String_comparison_exp
    target: holder_bool_exp
    target_address: String_comparison_exp
}

"order by max() on columns of table \"tzd_record\""
input tzd_record_max_order_by {
    domain_id: order_by
    id: order_by
    target_address: order_by
}

"order by min() on columns of table \"tzd_record\""
input tzd_record_min_order_by {
    domain_id: order_by
    id: order_by
    target_address: order_by
}

"Ordering options when selecting data from \"tzd_record\"."
input tzd_record_order_by {
    domain: tzd_domain_order_by
    domain_id: order_by
    id: order_by
    target: holder_order_by
    target_address: order_by
}

"Streaming cursor of the table \"tzd_record\""
input tzd_record_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: tzd_record_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input tzd_record_stream_cursor_value_input {
    domain_id: String
    id: String
    target_address: String
}

"Boolean expression to filter rows from the table \"tzd_tld\". All fields are combined with a logical 'AND'."
input tzd_tld_bool_exp {
    _and: [tzd_tld_bool_exp!]
    _not: tzd_tld_bool_exp
    _or: [tzd_tld_bool_exp!]
    domains: tzd_domain_bool_exp
    id: String_comparison_exp
    owner: String_comparison_exp
}

"Ordering options when selecting data from \"tzd_tld\"."
input tzd_tld_order_by {
    domains_aggregate: tzd_domain_aggregate_order_by
    id: order_by
    owner: order_by
}

"Streaming cursor of the table \"tzd_tld\""
input tzd_tld_stream_cursor_input {
    "Stream column input with initial value"
    initial_value: tzd_tld_stream_cursor_value_input!
    "cursor ordering"
    ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input tzd_tld_stream_cursor_value_input {
    id: String
    owner: String
}
